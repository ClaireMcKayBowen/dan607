[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Security, Privacy, and Ethics (+ Equity)",
    "section": "",
    "text": "Welcome to DAN 607\nThis Quarto book is the notes for DAN 607: Security, Privacy, and Ethics (+Equity) in the Business Analytics Program at Meehan School of Business within Stonehill College.",
    "crumbs": [
      "Welcome to DAN 607"
    ]
  },
  {
    "objectID": "index.html#course-meeting-time-edt",
    "href": "index.html#course-meeting-time-edt",
    "title": "Security, Privacy, and Ethics (+ Equity)",
    "section": "Course Meeting Time (EDT)",
    "text": "Course Meeting Time (EDT)\n\nMay 31st, Friday, 5:00 pm – 9:00 pm\nJune 7th, Friday, 5:00 pm – 9:00 pm\nJune 14th, Friday, 5:00 pm – 9:00 pm\nJune 21st, Friday, 5:00 pm – 9:00 pm\nJune 28th, Friday, 5:00 pm – 9:00 pm",
    "crumbs": [
      "Welcome to DAN 607"
    ]
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Security, Privacy, and Ethics (+ Equity)",
    "section": "Course Description",
    "text": "Course Description\nAt what point does the sacrifice to our personal information outweigh the public good? In a data-driven era, data users and researchers frequently leverage personal or confidential data to help policymakers make evidence-based, data-informed decisions, such as improving economic recovery or creating a more efficient COVID-19 vaccine distribution. However, access to confidential data comes with several privacy concerns, especially for underrepresented groups. Striking the right balance is crucial to avoid real disclosure risks that may not be obvious, like stalkers utilizing excessive location data or malicious parties learning sensitive medical information through linkable health or genetic data.\nThis course will cover the security, privacy, ethics, and equity considerations the U.S. government and private sector must navigate throughout the data life cycle: data acquisition or collection, data storage, data sharing and transfer, data analysis and dissemination, and data destruction or termination. Specifically, students will understand the legal, social, and ethical ramifications of data security and privacy as well as the concepts behind data guardianship, and custodianship, and data permissions.\nAt a high level, the main learning objectives/topic areas of this course are learning the:\n\nimportance of data security, privacy, ethics, and equity\nways experts develop privacy preserving methods throughout the data life cycle\nprivacy laws governing and protecting people’s information\nissues that society must consider advancing and improving security, privacy, ethics, and equity",
    "crumbs": [
      "Welcome to DAN 607"
    ]
  },
  {
    "objectID": "index.html#textbook-bowen2021protecting",
    "href": "index.html#textbook-bowen2021protecting",
    "title": "Security, Privacy, and Ethics (+ Equity)",
    "section": "Textbook (Bowen 2021)",
    "text": "Textbook (Bowen 2021)\nTitle: Protecting Your Privacy in a Data-Driven World\nAuthor: Claire McKay Bowen\nPublisher: Routledge\nISBN: 978-0367640743",
    "crumbs": [
      "Welcome to DAN 607"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Security, Privacy, and Ethics (+ Equity)",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThank you Aaron R. Williams for teaching me how to create a Quarto document/book for this course, which is what we use for all our teaching and training materials at the Urban Institute. Check out his Quarto book for his Data Science for Public Policy course in the McCourt School of Public Policy at Georgetown University.\nThank you also to my spouse and friends for reviewing some of the professional non-technical skills content and providing additional tips.\n\n\n\n\nBowen, Claire McKay. 2021. Protecting Your Privacy in a Data-Driven World. Chapman; Hall/CRC.",
    "crumbs": [
      "Welcome to DAN 607"
    ]
  },
  {
    "objectID": "01_introduction.html",
    "href": "01_introduction.html",
    "title": "1  DAN 607 Basics",
    "section": "",
    "text": "1.1 Goals and expectations\nThe primary aim is to foster an understanding of privacy, security, ethics, and equity when using data throughout its life cycle (i.e., from collection to termination). Throughout the course, we will explore the significance, historical context, current methodologies, privacy legislation, and forthcoming developments in this field.\nThe course is predominantly conceptual, recognizing that students will possess varying levels of analytical skills. I expect students to be actively engaged in discussions, which is why “Community Contributions” accounts for 25% of your grade. Half your grade is your writing assignments. Please take your writing assignments seriously. While I will not grade based on writing quality (this is not an English course), I do expect minimal typos, grammar, and mechanics errors. The purpose of the writing assignments is for you to reflect on the content you have learned and see how it applies to the real world, your potential professional work, community, and personal life.\nThe final will be a presentation. We will discuss further details about the presentation during our week 4 class on June 14th. The main reason I have chosen a presentation for your final is that verbal communication is crucial in most professions and is often not taught in courses. Part of our week 4 class will involve learning how to create better presentations and how to present more technical content to a broader audience.",
    "crumbs": [
      "Prelude",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>DAN 607 Basics</span>"
    ]
  },
  {
    "objectID": "01_introduction.html#developing-your-professional-skills",
    "href": "01_introduction.html#developing-your-professional-skills",
    "title": "1  DAN 607 Basics",
    "section": "1.2 Developing your professional skills",
    "text": "1.2 Developing your professional skills\nIn line with learning more professional non-technical skills (like week 4 class on presentations), each class will cover a professional topic, such as effective communication, in addition to learning about data security, privacy, ethics, and equity. The purpose of this is to provide additional information that is often not taught in courses, helping to prepare you for the professional environment.",
    "crumbs": [
      "Prelude",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>DAN 607 Basics</span>"
    ]
  },
  {
    "objectID": "01_introduction.html#assignments",
    "href": "01_introduction.html#assignments",
    "title": "1  DAN 607 Basics",
    "section": "1.3 Assignments",
    "text": "1.3 Assignments\nThe first assignment starts on day one (May 20) but is not due until the day before we first meet (May 30, at 11:59 PM EDT). Since all the assignments are listed out, you may choose to get a head start on them, but I advise pacing yourself with the class, as you will want the content you read and/or watch to be top of mind for in-class discussions.",
    "crumbs": [
      "Prelude",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>DAN 607 Basics</span>"
    ]
  },
  {
    "objectID": "01_introduction.html#missing-class-and-assignment-policy",
    "href": "01_introduction.html#missing-class-and-assignment-policy",
    "title": "1  DAN 607 Basics",
    "section": "1.4 Missing class and assignment policy",
    "text": "1.4 Missing class and assignment policy\nI will provide one unexcused absence for either a class or an assignment (not both). The grade for that class or assignment (since both are weighed equally for grading) will be waived in your final grade. If you miss additional classes and/or assignments, you will receive 0 points unless you have a medical emergency or a similar situation. In such cases, please speak with me or email me separately so we can discuss alternatives.\nAdditionally, I will allow one late assignment worth half of the points. If you were to receive top marks (25 points), you would receive half that instead (12.5 points).\nFor those requesting the class be recorded, I will ask those present if they are okay with recording the session and, if permitted, will upload the video on Canvas. I request that students do not download the video, as this might tempt some to share the recording externally. This act would violate the course’s purpose. If I become aware of such sharing, I will not record future class sessions. This class focuses on security, privacy, ethics, and equity. A student who shares the recording beyond the course violates these principles.",
    "crumbs": [
      "Prelude",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>DAN 607 Basics</span>"
    ]
  },
  {
    "objectID": "01_introduction.html#week-1-assignment",
    "href": "01_introduction.html#week-1-assignment",
    "title": "1  DAN 607 Basics",
    "section": "1.5 Week 1 Assignment",
    "text": "1.5 Week 1 Assignment\n\n\n\n\n\n\nDEADLINE\n\n\n\nDue May 30, at 11:59 PM EDT on Canvas\n\n\n\n1.5.1 Read\n\nChapter 1: Why Is Data Privacy Important?\nChapter 2: How Did Data Privacy Change Over Time?\n\n\n\n1.5.2 Watch\nCoded Bias (Netflix link). Please let me know ASAP if you cannot watch it.\n\n\n1.5.3 Write (600 to 1200 words)\nFind and summarize a real-world example of data being used unethically and/or had violated people’s privacy. The example must be recent (i.e., since 2021, so after all the examples listed in both “Coded Bias” and the book). Try to keep the following in mind:\n\nWhat is the example? Introduce the situation and explain why it is important, providing any relevant background for the reader.\nHow did the example demonstrate a violation of a person’s privacy? Does it apply to everyone or only a subgroup of people? Why is that?\nWhat are the takeaways from this situation? Has this situation been resolved? Why or why not?",
    "crumbs": [
      "Prelude",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>DAN 607 Basics</span>"
    ]
  },
  {
    "objectID": "01_introduction.html#week-2-assignment-no-writing",
    "href": "01_introduction.html#week-2-assignment-no-writing",
    "title": "1  DAN 607 Basics",
    "section": "1.6 Week 2 Assignment (No writing)",
    "text": "1.6 Week 2 Assignment (No writing)\nNo writing assignment. Make sure to complete week 1 writing assignment.\nCome prepared to be engaged in discussion about the various ways data is collected.\n\n1.6.1 Read\n\nDo No Harm Guide: Collecting, Analyzing, and Report Gender and Sexual Orientation Data – Parts 1, 2, and 3.",
    "crumbs": [
      "Prelude",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>DAN 607 Basics</span>"
    ]
  },
  {
    "objectID": "02_security-privacy-ethics-equity.html",
    "href": "02_security-privacy-ethics-equity.html",
    "title": "2  Security, Privacy, Ethics, and Equity",
    "section": "",
    "text": "2.1 How well do you know about basic corporate and governmental internet practices and policies",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Security, Privacy, Ethics, and Equity</span>"
    ]
  },
  {
    "objectID": "02_security-privacy-ethics-equity.html#how-well-do-you-know-about-basic-corporate-and-governmental-internet-practices-and-policies",
    "href": "02_security-privacy-ethics-equity.html#how-well-do-you-know-about-basic-corporate-and-governmental-internet-practices-and-policies",
    "title": "2  Security, Privacy, Ethics, and Equity",
    "section": "",
    "text": "2.1.1 Test your knowledge\n\n\n\n\n\n\nClass Activity 1\n\n\n\nComplete this 17 true-or-false question quiz created by researchers from the Annenberg School for Communication at the University of Pennsylvania (Turow et al. 2023).\nYou will have 6 minutes to complete it (it should take you roughly 3 to 4 minutes).\n\n\n\n\n\n\n\n\nFigure 2.1: The cover of the Annenberg School for Communication at the University of Pennsylvania report, “American’s Can’t Consent to Companies’ Use of Their Data.”\n\n\n\n\n\n\n\n\n\nANSWERS BEYOND THIS POINT!\n\n\n\nAnswers to each question are beyond this point along with additional information. Please do not proceed until you have completed the quiz!\n\n\n\n\n2.1.2 Answers to the quiz and discussion\n\n\n\n\n\n\nClass Activity 2\n\n\n\nWe will review the answers to the quiz along with additional information that helps answer those questions.\n\nDid the answer surprise you? Why or why not?\nWhat assumptions did you have prior to knowing the answer?\nWhat answer would you prefer? What steps would be necessary for the answer to change? For example, if the answer is “False,” would you rather the answer be “True”? If so, what would it take to make the statement true?\n\n\n\n\n\n\n\n\n\nWhen I go to a web site, it can collect information about my online behaviors even if I don’t register using my name or email address.\n\n\n\n\n\nTRUE\nFrom Turow et al. (2023),\n\nCompanies have an ability to see what we do on our websites and apps (through first-party cookies and other such trackers); to follow us across the media content we visit (via third-party cookies and emerging versions); to view our activities as we move from one media technology to another— for example, from the web to our smartphone to our tablet to our “connected” TV to the in-store trackers we pass in the aisles, to outdoor message boards we stop to view. Whether with first- party data, third-party data, or more, the goal is to give us tags or personas and have computers decide whether and how we ought to be the companies’ targets.\n\n\n\n\n\n\n\n\n\n\nA Smart TV can help advertisers send an ad to a viewer’s smartphone based on the show they are watching.\n\n\n\n\n\nTRUE\nSee answer to question 1.\n\n\n\n\n\n\n\n\n\nA company can tell that I have opened its email even if I don’t click on any links.\n\n\n\n\n\nTRUE\nEmail tracking is a method that sends a signal to the sender’s server that the email has been opened. Many services use this method (the Urban Institute does this for their newsletters!). However, some email providers, such as Outlook and Gmail, have features that can block this type of tracking. You should check your email settings.\n\n\n\n\n\n\n\n\n\nA website cannot track my activity across devices unless I log into the same account on those devices.\n\n\n\n\n\nFALSE\nSee the answers to the previous questions. Cookies, IP address tracking, email tracking, and more can be linked together to track an individual across devices (although the accuracy might be reduced, such as being coarsened to the household level).\n\n\n\n\n\n\n\n\n\nWhen a website has a privacy policy, it means the site will not share my information with other websites or companies without my permission.\n\n\n\n\n\nFALSE\nA privacy policy does not mean a site won’t share a person’s information with other sites without the person’s permission.\nChrome’s New Privacy Policy \n\n\n\n\n\n\n\n\n\nFacebook’s user privacy settings allow me to limit the information about me that Facebook shares with advertisers.\n\n\n\n\n\nTRUE\nCheck all the apps you use to adjust your privacy settings!\n\n\n\n\n\n\nFigure 2.2: A screenshot of updating one’s ad preferences for their Facebook account.\n\n\n\n\n\n\n\n\n\n\n\n\nAll fifty states have laws requiring companies to notify individuals of security breaches involving personally identifiable information.\n\n\n\n\n\nTRUE\nThere was a recent Federal Register Notice (FRN)1 on “Data Breach Reporting Requirements.”\n\n\n\n\n\n\nFigure 2.3: A screenshot of the “Data Breach Reporting Requirements” Federal Register Notice.\n\n\n\n\n\n\n\n\n\n\n\n\nIt is illegal for internet marketers to record my computer’s IP address.\n\n\n\n\n\nFALSE\nThere is no federal law in the United States that protects consumer data privacy.\n\n\n\n\n\n\n\n\n\nIt is legal for an online store to charge people different prices depending on where they are located.\n\n\n\n\n\nTRUE\nThink about your local area and whether grocery stores change the prices of their goods based on their proximity to certain neighborhoods.\n\n\n\n\n\n\n\n\n\nThe doorbell company Ring has a policy of not sharing recordings with law enforcement without the homeowner’s permission.\n\n\n\n\n\nTRUE\nCheck out this Associate Press article about the new policy!\n\n\n\n\n\n\nFigure 2.4: Screenshot from the Associate Press article.\n\n\n\n\n\n\n\n\n\n\n\n\nBy law, a travel site such as Expedia or Orbitz that compares prices on different airlines must include the lowest airline prices.\n\n\n\n\n\nFALSE\nThere are no United States laws mandating that such travel sites offer the lowest airline prices.\n\n\n\n\n\n\n\n\n\nIn the United States, the federal government regulates the types of digital information companies collect about individuals.\n\n\n\n\n\nFALSE\nAgain…THERE IS NO FEDERAL CONSUMER DATA PRIVACY LAW!\n\n\n\n\n\n\n\n\n\nSome large American cities have banned the use of facial recognition technology by law enforcement.\n\n\n\n\n\nTRUE\nSan Francisco became the first United States city to ban facial recognition.\nBBC article\nNYTimes article\n\n\n\n\n\n\n\n\n\nThe US Federal government requires that companies ask internet users to opt-in to being tracked.\n\n\n\n\n\nFALSE\nFor the third time, THERE ARE NO FEDERAL DATA PRIVACY LAWS!\nIn the United States, what you encounter on sites that prompt you to choose are usually ‘opt-out’ settings. If there’s an ‘opt-in’ alternative, it’s often because website designers have streamlined the site, not wanting to differentiate visitors from the United States or European Union countries, which have ‘opt-out’ data privacy laws\n\n\n\n\n\n\n\n\n\nSection 230 of the Communication Decency Act ensures that digital platforms like Facebook, Twitter, and YouTube can be held responsible for illegal content posted on their platforms.\n\n\n\n\n\nFALSE\nFrom Section 230 of the Communication Decency Act:\n\nNo provider or user of an interactive computer service shall be treated as the publisher or speaker of any information provided by another information content provider.\n\n\n\n\n\n\n\n\n\n\nThe Health Insurance Portability and Accountability Act (HIPAA) prevents apps that provide information about health from selling data collected about app users to marketers.\n\n\n\n\n\nFALSE\nFrom Turow et al. (2023),\n\nThe Federal Health Insurance and Portability Act (HIPAA) does not stop apps that provide information about health – such as exercise and fertility apps – from selling data collected about the app users to marketers. HIPAA came into law in 1996 to “improve portability and continuity of health insurance coverage in the group and individual markets, to combat waste, fraud, and abuse in health insurance and health care delivery, to promote the use of medical savings accounts, to improve access to long-term care services and coverage, to simplify the administration of health insurance, and for other purposes.” Therefore, HIPAA does not prevent apps that provide information about health from selling data collected about app users to marketers.\n\n\n\n\n\n\n\n\n\n\nSome social media platforms activate users’ smartphone speakers to listen to conversations and identify their interests in order to sell them ads.\n\n\n\n\n\nFALSE\nThere has never been a documented case of a social media platform activating users’ smartphone speakers to eavesdrop on conversations and identify their interests for targeted advertising. Your browsing history already furnishes enough information for that!",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Security, Privacy, Ethics, and Equity</span>"
    ]
  },
  {
    "objectID": "02_security-privacy-ethics-equity.html#what-is-data-security-privacy-ethics-and-equity",
    "href": "02_security-privacy-ethics-equity.html#what-is-data-security-privacy-ethics-and-equity",
    "title": "2  Security, Privacy, Ethics, and Equity",
    "section": "2.2 What is data security, privacy, ethics, and equity?",
    "text": "2.2 What is data security, privacy, ethics, and equity?\nFor this week, you were assigned to read the first two chapters of the textbook, watched “Coded Bias,” researched a real-world example of data being used unethically and/or violated people’s privacy.\n\n\n\n\n\n\nClass Activity 3\n\n\n\nDrawing from the readings, documentaries, and your assignment, let’s delve into the following:\n\nWhat data did AI, algorithms, or the example you found use to determine what you see?\nDoes the scenario you mentioned apply to everyone or only to a specific subgroup of individuals? Why or why not?\nCould the scenario you brought up be used for a public good? If so, what changes would be necessary to create a public good?\nDoes those changes involve security, privacy, ethics, and equity?\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nDid you notice that the AI narrator in “Coded Bias” speaks with a female voice.\nConsider other AI interfaces we interact with daily. Do they also predominantly feature a female voice? What biases might this perpetuate within society?\n\n\nScarlett Johansson says she is ‘shocked, angered’ over new ChatGPT voice - NPR Article\n\n\n\n\n\n\nFigure 2.5: Screenshot of the NPR article.\n\n\n\n\n2.2.1 Defining key stakeholders in the data ecosystem\nFor this course, this is how we define the various stakeholders in the data ecosystem.\n\n\n\n\n\n\nFigure 2.6: Key stakeholders in the data ecosystem\n\n\n\n\n\n2.2.2 Security, Privacy, and Confidentiality\n\n\n\n\n\n\nData Security\n\n\n\nData Security is the “…science of methods of protecting computer data and communication systems that apply various types of controls such as cryptography, access control, information flow paths and inference control, including backup and recover” (Denning 1982).\n\n\nData security often refers to the hardware, software, storage devices, and user devices; access and administrative controls; and organizations’ policies and procedures. For example, many organizations have switched to two factor authentication and VPN to access their systems.\n\n\n\n\n\n\nData Privacy\n\n\n\nData Privacy is the ability “to determine what information about ourselves we will share with others” (Fellegi 1972). Data privacy is a broad topic, which includes data security, encryption, access to data, etc. We will not be covering privacy breaches from unauthorized access to a database (e.g., hackers).\n\n\n\n\n\n\n\n\nConfidentiality\n\n\n\nConfidentiality is “the agreement, explicit or implicit, between data subject and data collector regarding the extent to which access by others to personal information is allowed” (Fienberg and Jin 2018).\n\n\n\nThere are at least three major threats to data security and privacy.\n\nHackers: adversaries who steal confidential information through unauthorized access.\nSnoopers: adversaries who reconstruct confidential information from data releases.\nHoarders: stewards who collect data but don’t release the data even if respondents want the information releasesd.\n\nThere are differing notions of what should and shouldn’t be private, which may include being able to opt out of or opt into disclosure protections.\nData privacy is a broad topic, which includes data security, encryption, access to data, etc. We will not be covering privacy breaches from unauthorized access to a database (e.g., hackers).\n\n\n\n2.2.3 Ethics and Equity\n\n\n\n\n\n\nEthics\n\n\n\nData ethics is the “…systemizing, defending, and recommending concepts of right and wrong conduct in relation to data, in particular personal data” (Kitchin 2014).\n\n\nMost research institutions and government entities have an Institutional Review Board (IRB), an institution that applies research ethics by reviewing the methods proposed for research involving human subjects, to ensure that the projects are ethical. IRBs do not evaluate the quality of the research. They evaluate the the ethical protection of human subjects.\n\n\n\n\n\n\nEquity\n\n\n\nData Equity is …\n\nrepresentation\naccess\nprocess\noutcomes\nand more\n\n\n\nData equity is also a complex concept, which should be thought of throughout the data life cycle. How do we ensure people are properly represented in data or various organizations in the United States have access to that data to better communities?\n\n\n\n\n\n\nClass Activity 4\n\n\n\n\nPrior to starting this course, how would you have defined data security, privacy, ethics, and equity?\nHow has your definition of these different terms changed since the assignments and these discussions? Why or why not?",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Security, Privacy, Ethics, and Equity</span>"
    ]
  },
  {
    "objectID": "02_security-privacy-ethics-equity.html#data-life-cycle",
    "href": "02_security-privacy-ethics-equity.html#data-life-cycle",
    "title": "2  Security, Privacy, Ethics, and Equity",
    "section": "2.3 Data life cycle",
    "text": "2.3 Data life cycle\nWe’ve just started exploring the world of security, privacy, ethics, and equity. Throughout this course, we’ll integrate these definitions, concepts, and ideas into our discussions, applying them to the data life cycle, which we define as:\n\ndata collection or acquisition (week 2)\ndata storage (week 3)\ndata sharing and transfer (week 3)\ndata analysis (week 4)\ndata dissemination (week 5)\ndata destruction or termination (week 6)\n\n\n\n\n\n\n\nNo set taxonomony in the field!\n\n\n\nAll definitions used (including the data life cycle) are my opinionated definitions. Since many different fields work in data security, privacy, ethics, and equity, there is no standard taxonomy, which causes a lot of confusion. I set a standard definition in all my work, including this course, to ensure we are using the same common language. However, note that when reading other materials or literature, you might encounter conflicting terminology.\n\n\n\n\n\n\nDenning, Dorothy Elizabeth Robling. 1982. Cryptography and Data Security. Vol. 112. Addison-Wesley Reading.\n\n\nFellegi, Ivan P. 1972. “On the Question of Statistical Confidentiality.” Journal of the American Statistical Association 67 (337): 7–18.\n\n\nFienberg, Stephen E, and Jiashun Jin. 2018. “Statistical Disclosure Limitation for~ Data~ Access.” In Encyclopedia of Database Systems (2nd Ed.).\n\n\nKitchin, Rob. 2014. The Data Revolution: Big Data, Open Data, Data Infrastructures and Their Consequences. Sage.\n\n\nTurow, Joseph, Yphtach Lelkes, Nora Draper, and Ari Ezra Waldman. 2023. “Americans Can’t Consent to Companies’ Use of Their Data: They Admit They Don’t Understand It, Say They’re Helpless to Control It, and Believe They’re Harmed When Firms Use Their Data–Making What Companies Do Illegitimate.” Say They’re Helpless to Control It, and Believe They’re Harmed When Firms Use Their Data–Making What Companies Do Illegitimate (February 15, 2023).",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Security, Privacy, Ethics, and Equity</span>"
    ]
  },
  {
    "objectID": "02_security-privacy-ethics-equity.html#footnotes",
    "href": "02_security-privacy-ethics-equity.html#footnotes",
    "title": "2  Security, Privacy, Ethics, and Equity",
    "section": "",
    "text": "FRN is for proposed rule-makings and updates, proposed settlements, public meetings and workshops, and other important agency activities.↩︎",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Security, Privacy, Ethics, and Equity</span>"
    ]
  },
  {
    "objectID": "02_written-verbal-communication.html",
    "href": "02_written-verbal-communication.html",
    "title": "3  Written and Verbal Communication",
    "section": "",
    "text": "3.1 Hello. My name is Inigo Montoya…\nThis is a popular meme, and one I like a lot, that covers all the essential aspects when reaching out to someone for the first time or after a prolonged period.\nSimilarly in Glickman (2011), the “hello” is three parts:\nI will focus on this structure from Glickman (2011).",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Written and Verbal Communication</span>"
    ]
  },
  {
    "objectID": "02_written-verbal-communication.html#hello.-my-name-is-inigo-montoya",
    "href": "02_written-verbal-communication.html#hello.-my-name-is-inigo-montoya",
    "title": "3  Written and Verbal Communication",
    "section": "",
    "text": "Figure 3.2: One of the most famous quotes from the movie, “The Princess Bride,” where the Inigo Montoya faces the man who killed his father.\n\n\n\n\nBe polite\nProvide your name\nState your relationship\nManage expectations\n\n\n\nIntroduction\nPurpose of your call or email\nKey question\n\n\n\n3.1.1 Introduction\nThe general idea here is to avoid assuming that everyone knows who you are, your affiliation with a school or company, or how you were connected to them.\nI took a similar approach in our initial email exchange for this course. Given my role as an adjunct professor rather than full-time faculty at Stonehill College, I’ve provided a more detailed introduction to offer some background.\n\n\n\n\n\n\nEmail to 2024 DAN 607 Students\n\n\n\nDear Students,\nI am Claire Bowen, your instructor for DAN 607: Security, Privacy, and Ethics. I am a senior fellow and lead the Data Governance and Privacy Team at the Urban Institute; a non-profit, non-partisan, public policy research institute HQed in Washington DC. However, I am a remote worker in Santa Fe, NM. My research focuses on developing technical and policy solutions aimed at safely expanding access to confidential data for advancing evidence-based policy-making. If interested, you can learn more here.\n[removed rest of the email to focus on the introduction]\n\n\nThis next example is how a colleague introduced himself to me. Even though he worked at Urban at the same time I did, several months had passed, and we never worked on a project together. He didn’t presume that I remembered him and made sure to clearly state who he is and our prior connection.\n\n\n\n\n\n\nEmail about data sharing\n\n\n\nHi Claire,\nThis is Eric Smith – a former colleague from Urban. I’m currently on detail to the Treasury Department, where I sit on the racial equity team here supporting on efforts related to research and data. A big part of my role is engaging with the Office of Tax Policy on efforts related to equity and tax administration.\n[removed the middle part of the email to focus on the introduction]\nI can share more once we find a time to talk. Would you have time to chat this week? Sooner would be preferable if that works.\nThanks,\nEric\n\n\nHere’s another example, this time introducing two individuals I know to each other. I’ve embedded links to help them learn more about each and their work as well as relevant references.\n\n\n\n\n\n\nEmail to connect two colleagues about the new Do No Harm Guide on SOGI\n\n\n\nGood morning Jon,\nI hope you’re doing well.\nI would like to introduce you to Naomi Goldberg, the incoming Executive Director of the Movement Advancement Project. She recently saw the latest Do No Harm Guide on Collecting, Analyzing, and Report Gender and Sexual Orientation Data and wanted to connect with the people behind the report.\nNaomi, this is Jon Schwabish, senior fellow in the Income and Benefits Policy Center at the Urban Institute. He is the mastermind on the Do No Harm Guide project, a series of guides on how researchers and practitioners can better approach their work with a DEI lens.\nPlease let me know if you need anything else.\nClaire\n\n\n\n\n\n\n\n\nImportant\n\n\n\nPlease note that I didn’t spell out “DEI” because I assumed both individuals, given their line of work, were familiar with the term. However, it’s generally advisable not to make this assumption unless you’re almost certain!\nAlso, I kept their names since I link to their profiles and their bodies of work.\n\n\n\n\n3.1.2 Purpose\nNext, it’s crucial to clearly state the purpose of the conversation. This should follow immediately after the introduction and should be concise, ideally in one or two sentences. The goal of any verbal and written communication is to ensure clarity within the first three sentences, as most people are busy and tend to skim emails or only listen for the first 15 seconds. This approach helps the recipient prioritize their responses, especially in cases where they receive a high volume of emails, such as myself, who typically receives around 50 emails a day.\nIn this next example, I’m reaching out to colleagues at a state office following a training session on data privacy techniques, specifically synthetic data generation. Given our recent communications, I skipped reintroducing myself and proceed directly to the purpose of this email after a brief greeting.\n\n\n\n\n\n\nEmail to state colleagues on next steps for a project at Urban\n\n\n\nGood morning everyone,\nI hope you are doing well and had a wonderful weekend.\nThe Urban team is reaching out to discuss scheduling office hours or support sessions to aid the state staff in implementing the required modifications to the tidysynthesis and syntheval code for generating synthetic data.\nPlease let us know of your preferred start time for these sessions, their frequency, and any additional support you may need.\nWe look forward to continuing to work with you.\nClaire\n\n\n\n\n3.1.3 Key question\nMake sure to have the specific ask or key question in the verbal or written exchange, such as:\n\nDo you have a few minutes to talk about kicking off the project?\nIs this a good time to talk about the updates to the performance management process?\nCould you send the document that we discussed at in our check-in meeting last week?\nI am trying to reach Mike in Accounting. Do you have his contact information?\n\nIn the previous example, my key question is what is the preferred start time for the “office hours” or “support sessions” to aid the state staff members.\nThis next example is an email from someone asking me to write a letter of recommendation.\n\n\n\n\n\n\nClass Activity 1\n\n\n\nWhat is missing from this email based on suggested structure we covered for an introduction email?\n\n\n\n\n\n\n\n\nAward nomination\n\n\n\nDear Claire,\nI am working to submit a nomination for Emilee Allen for the ASA mentoring award; see https://www.amstat.org/your-career/awards/asa-mentoring-award. Emilee identified you as someone who could speak to her mentoring impact on your career, so I was hoping to get your help.\nIf you could either:\n\nProvide me with a few sentences on the impact of Emilee’s mentoring on your career. If any of that interaction was in the early part of your career, please stress those points (per the ASA announcement). OR\nWrite a letter of support – which can be no more than 2 pages – to include in the submission.\n\nIf you are willing to write a letter I can pull from that to write the overall nomination.\nI know you are extremely busy, so I would be very appreciative of any information you can provide.\nThe nomination package is due March 1st, but I am hoping to have all information assembled by February 1.\nPlease hit reply all to this email as I am CCing my new email at the University at Buffalo (where I will start as Chair of Biostatistics in February).\nThank you for considering.\nBest,\nDaniel\n\n\n\n\n3.1.4 Make requests into questions\nIn addition to Glickman (2011)’s structure, frame your requests into questions. Often our first emails to someone new are because we need to ask them something. This is already hard for verbal communication let alone written communication, where tone is hard to convey. If you have a request for someone, rephrase it like a question. It will sound more like the intent (a request) rather than a demand.\n\n\n\n\n\n\nOriginal email\n\n\n\nHi Steve,\nI’m Karen, a program manager for the project. Per our meeting, I need you to work with Jeff and Brandon to give me yours’ and your team’s FTE1 to finalize the budget. Give me that information by COB2 5/12.\nKaren\n\n\nThe email follows the recommended structure, but the tone is off because the request sounds like a demand. Additionally, Jeff and Brandon, who weren’t at the meeting, were CCed in the original email. If the request is phrased as a question and a comment is made about the CCed individuals, the tone will come across much lighter.\n\n\n\n\n\n\nFigure 3.3: Really, Karen?\n\n\n\n\n\n\n\n\n\nModified version of the previous email\n\n\n\nHi Steve,\nI’m Karen, a program manager for the project. Per our meeting on Tuesday, I need to finalize the project’s budget and have a deadline to get completed by 5/20. Would it be possible for you to get me your team’s FTE by 5/12?\nI’ve cced Jeff and Brandon for their awareness since I need their rates too.\nKaren",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Written and Verbal Communication</span>"
    ]
  },
  {
    "objectID": "02_written-verbal-communication.html#how-to-say-goodbye",
    "href": "02_written-verbal-communication.html#how-to-say-goodbye",
    "title": "3  Written and Verbal Communication",
    "section": "3.2 How to say “goodbye”",
    "text": "3.2 How to say “goodbye”\nFor most hello or introduction written and verbal communication, you want to have “next steps”, “action items”, or some sort of “forward momentum” (as Glickman (2011) refers to it). After you achieve your goal of your initial communication (was it a follow-up conversation or completing a task), you should keep the door open in some way.\nThe goodbye should include these two parts.\n\nThank you\nForward momentum\n\n\n3.2.1 Always thank people for their time\nEven if the conversation or interaction wasn’t productive or had the desired outcome, it’s always important to express gratitude for people’s time and effort. Being polite can go a long way. Also, people loved being thanked!\n\n\n\n\n\n\nFigure 3.4: Thank you, thank you, thank you from Ke Huy Quan at the 2024 Oscars\n\n\n\nThe following is an email from a colleague who had asked me about how to explain a privacy concept, differential privacy, at a high level for a presentation. Below is his response after I took the time to provide him with a high-level conceptual example. Notice that he thanked me several times throughout the email, which I bold.\n\n\n\n\n\n\nConceptual question on differential privacy\n\n\n\nThanks Claire:\nGreat insight, very helpful. It’s an interesting exercise that helps me better understand what’s going on. The strategic spending of privacy bucks suggest some design/strategy ideas (giving away my operations research degree)…in some settings, it might be worth asking the same question a few times to get a sense of variability (with a cap on the number of questions, you might not be able to ask enough times to get a good estimate of the variance, but you might gain insight on the potential magnitude to some order…).\nThanks for the thoughts on this, I’m going to the Federal Cmt on Stat Methods next week and am summarizing some of our work…there are other talks in my session on DP, specifically, but I wanted to have an intuition-building statement before jumping to results. This was great. I’ll keep thinking about it and feel free to send any further thoughts. You do a really nice job of explaining these issues!\nThanks again for the time and thoughts!\nJohn\n\n\n\n\n3.2.2 Forward momentum / next steps\nAs Glickman (2011) states,\n\nEvery conversation presents an opportunity to build upon and expand your network. With each new itneraction, you have an opportunity to establish or build rapport and leverage professional relationships going forward. Building on the “thank you” is where the true skill comes in.\n\nThere are numerous methods to sustain that momentum or identifying potential next steps. This could be as straightforward as saying, “I look forward to staying in touch.” or suggesting, “Let’s connect on LinkedIn.” The latter is my go to, especially when meeting people at networking events like professional conferences. It’s a low effort way of staying connected in some way.\nIn the following example, staff from the a state’s Department of Health contacted me regarding alternative data privacy methods aimed at avoiding the suppression or removing public health data records. The forward momentum is opening the door for further questions.\n\n\n\n\n\n\nVirtual meeting with a state’s Department of Health\n\n\n\nAt the end of the 30 minute meeting, the staff thanked me for my time. I then concluded the conversation by extending an invitation for the staff members at the state’s Department of Health to reach out me at a later time if they had any further questions. The hope is that they may want to partner on a project on how to safely expand access to their health data for rural communities.\n\n\nI met a colleague at a workshop, and we discussed a job posting in his organization and his difficulties finding qualified candidates. I offered to help spread the word if he forwarded me the posting, which was my forward momentum in the in-person exchange. My colleague then seized that forward momentum by sending an email that evening.\n\n\n\n\n\n\nSharing a job posting\n\n\n\nClaire,\nIt was nice to get a chance to talk to you today. We have extended the posting to Nov. 13, 2023 so if you have places you can circulate the ad, I would be most appreciative. If there are people you think I should reach out to recruit, I’m happy to do so.\nLINK\nThanks!\nJules\n\n\nThe following next example is an email after I conducted an informational interview about Urban Institute with someone who recently graduated college.\n\n\n\n\n\n\nClass Activity 2\n\n\n\nWhat is missing from this email based on what is recommended for a goodbye email?\n\n\n\n\n\n\n\n\nUrban Institute opportunities\n\n\n\nHi Claire,\nThank you again for taking the time to speak with me yesterday! I loved getting to hear more about the Urban Institute and how it engages with current issues to seek to build a better society, and I appreciate your willingness to share some about your own journey and experiences. It’s inspiring to learn about the different paths people take to find what they are passionate about and discover ways to put those passions into practice for the good of others. Thank you as well for your advice regarding communication skills as I apply for Urban Institute, and for your encouragement to explore my interests and passions. I look forward to discovering where my path leads!\nBest,\nJane\n\n\nDon’t fall into the abyss! Try to make sure the new connection remembers you!\n\n\n\n\n\n\nFigure 3.5: A giant statue of Bender from the TV show, Futurama, with text saying, “Remember me.”",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Written and Verbal Communication</span>"
    ]
  },
  {
    "objectID": "02_written-verbal-communication.html#foolproof-download",
    "href": "02_written-verbal-communication.html#foolproof-download",
    "title": "3  Written and Verbal Communication",
    "section": "3.3 Foolproof download",
    "text": "3.3 Foolproof download\nGlickman describes three broad areas for providing a foolproof download, which is the most common form of professional communication you’ll use to share information with your coworkers and colleagues.\n\nThe status update - sharing information that is new, different, and/or important\nThe persuasive argument - making the case for someone to take action\nMissing/outstanding information - sharing news in the face of imperfect information\n\nSimilar to the previous section, we will examine the components/recipe for these types of information and provide real examples. This section is a little repetitive, so you can skip parts of it and reference the examples later.\n\n3.3.1 The status update\nFor status updates, the basics are:\n\nThe punchline\nKey facts / supporting highlights\nForward momentum\n\nThe purpose of this type of communication is to provide new, different, and/or important information. When drafting your email or considering what to say, think about your objective or what you hope to achieve from the conversation.\n\nIn the following example, people at Urban wanted to invite an expert on propensity score methods for causal effects to give a mini training session/course on the topic. Since I have both a professional and personal relationship with this expert, no introduction sentence is necessary.\n\n\n\n\n\n\nInvitation to speak at Urban on propensity score methods\n\n\n\nHi Sarah,\nI’m reaching out to you to see if would be willing to come to Urban in-person to give a talk. In 2022, lots of people really enjoyed your talk and conversations, so we’d love to have you back. [punchline]\nThe researchers in the Impact Methods group (Hanson is the contact person and is cced to this email) and the Statistical Methods Group are hoping that you would teach about use of propensity score methods (PSM) for impact analysis. Perhaps a talk along the lines of your presentation on the “Why, When, and How of PSM for Causal Effects” (that Ben found online, also cced to the email). The goal would be to give folks a grounding in what PSM is, how it works, when it’s useful vs. a bad idea, things to check to make sure it’s used properly, and pitfalls and potential solutions. Do you have a take on a good length for this workshop/talk? If an hour seems too tight, we’re thinking that 90 minutes would be fine too. If it works for you, we’d also like you to talk with folks before and after your talk. [key facts]\nIs scheduling something between now and June still possible? We’ve got a budget to cover your time as we did before.\nPlease let me know your thoughts on this. [next steps]\nLooking forward to hearing from you soon and catching up!\nClaire\n\n\nAfter several exchanges, the following is another example of the status update that follows the “punchline”, “facts / supporting highlights”, and “forward momentum” parts.\n\n\n\n\n\n\nInvitation to speak at Urban on propensity score methods (after several more email exchanges)\n\n\n\nHi Sarah,\nThank you for your patience! After some internal discussion, we were wondering if you would be open to sending a few introduction slides on propensity score methods (PSM). These slides would serve as a basis for a pre-session targeted at junior staff and those unfamiliar with PSM, likely led by Matt at Urban. This pre-session would also help us promote your talk. [punchline]\nFor the main talk, we propose that you spend 10 to 15 minutes providing an introduction to ensure everyone is aligned on key terminology and concepts before delving into more intermediate topics for the rest of the 90 minutes, followed by advanced topics during the discussion portion. This structure would also allow attendees the option to come back or leave early after the lunch break, depending on their interest on more advance topics. [key facts]\nThe outline could be:\n\nPSM talk (90 minutes)\n\n10 to 15 minutes on intro to PSM\n75 minutes on more intermediate PSM concepts\n\nBreak (30 to 45 minutes - lunch break)\nDiscussion (45 minutes)\n\nAdvance PSM topics + Q&A\n\n\nPlease let us know your thoughts! [next steps]\nClaire\n\n\nThe next example is an email from my colleague to our client about updating the bi-weekly check-ins for a project.\n\n\n\n\n\n\nScheduling check-ins starting in May\n\n\n\nHi Kristen,\nI hope you are well!\nClaire and I have been working on finding a time to schedule our biweekly check-ins later into the spring and summer. [punchline]\nCurrently, we still have meetings on the calendar until April 23rd. It looks like Thursdays from 1-2pm ET starting from May 9th would work best for the project team. Would you be available during that time frame? Though we hope additional Organization A folks would be able to make that time as well, we thought it most efficient to touch base with you first. [key facts]\nIf that time does not work for you, would you be able to provide some tentative days/times that typically work for you? Please also let us know if you would prefer to keep the current window (Tuesdays from 3-4pm ET). [next steps]\nThanks so much!\nPaige\n\n\n\n\n3.3.2 The persuasive argument\nSimilar to the status update, the persuasive argument has making your case as part of the punchline.\n\nThe punchline: make your case\nKey facts / supporting highlights\nForward momentum\n\nIt’s more crucial than ever to clearly state your case or the point you want to make. It also doesn’t hurt to be overly polite either!\nMight increase your chances…\n\n\n\n\n\n\nFigure 3.6: From the Dungeons & Dragons TV show, “Encounter Party!”, where someone is saying, “Can I roll persuasion?”\n\n\n\nThe following example is an exchange with the person who nominated me to be an award in 2023. Since the nomination failed, I reached out to my colleague about making a case to try again instead of waiting another year.\n\n\n\n\n\n\nNomination round 2\n\n\n\nHi Ali,\nI hope this message finds you well.\nI’ve been giving some thought to the possibility of making another attempt at the award nomination, and I wanted to discuss it with you. I think we should try again this year (2024). [punchline/case]\nTrying again wouldn’t be as arduous as last time, with only updates/edits needed for the new nomination. The downside is we need to reach out to letter writers again. [key facts]\nWhat are your thoughts? [next steps]\nClaire\n\n\nThis next example involves me reaching out to several colleagues to nominate a mutual colleague for an award, which will require several letters of recommendation (good letters take a lot of time to write!).\n\n\n\n\n\n\nClass Activity 3\n\n\n\nWhat could be done to make the following email better?\n\n\n\n\n\n\n\n\nNominating Amy for an award\n\n\n\nDear colleagues,\nI’m writing to discuss the possibility of nominating Amy for THE AWARD, recognizing individuals who have significantly contributed to advancing opportunities for women in statistics. [punchline/case]\nIn addition to her numerous accomplishments for our profession, I have been fortunate to benefit from Amy’s mentorship throughout my career. We initially connected at my first Joint Statistical Meetings3, where Amy reached out to me afterward to maintain our connection and provide me an opportunity to present at NSF/NCSES4. Since then, we have met at every Joint Statistical Meetings and other events, engaging in discussions on identifying research problems, navigating career transitions, addressing the challenges of the two-body problem, maintaining work-life balance, and more. [key facts]\nPrior to approaching Amy regarding this nomination, I wished to reach out to you—her esteemed colleagues throughout her career—to gauge alignment on whether Amy exemplifies the values and accomplishments akin to THE AWARD. I fully acknowledge that I am biased in believing she should be nominated for this award, which is why I am reaching out to you. Should you agree and upon securing Amy’s consent for the nomination, would you or someone within your network agree to drafting a letter of recommendation? The application deadline is Dec. 15, and I will ensure timely reminders to facilitate our submission process. [next steps]\nYour thoughts and comments are appreciated!\nClaire\n\n\n\n\n3.3.3 Missing/outstanding information\nFor this type of communication, the second part is highlighting the outstanding items.\n\nThe punchline: status update\nOutstanding items\nForward momentum\n\nWe often need to discuss missing information or identifying next steps for a situation or project. Sometimes, we find ourselves in conversations that have become so convoluted that we have no idea what is going on. If you find yourself in this situation, start from scratch and try to level set for all parties involved.\nBelow is part of an email exchange, where there was confusion about payments for a contract between Organization A and Urban Institute (my project). In this email, I try to establish what is known to figure out what we are missing and identify the next steps.\n\n\n\n\n\n\nContract confusion\n\n\n\nHi everyone,\nI wanted to touch base and ensure we’re on the same page about the contract between Organization A and Urban. There seems to be some uncertainty about the duration and amounts. [punchline]\nAttached is the original Urban subgrant agreement, which states two project years: Year 1 spanning from February 2023 to January 2024, and Year 2 spanning from February 2024 to January 2025. According to the agreement, the first payment of $13,920 was due on February 1, 2023, with the second payment of $6,960 scheduled for March 1, 2024.\nOrganization A has already issued the payment for Year 1, and the first email in this email thread contains the invoice Kevin (Urban) sent for Year 2. [outstanding items]\nErin, could you clarify whether your previous email confirms Organization A’s intent to pay Year 2? If not, could you and/or Gabe provide an explanation for this decision? [next steps]\nThank you for your attention to this matter. I hope this clarifies things.\nClaire\n\n\nFor the next email, I reached out to the staff in charge of travel approvals. I received several notifications about how my travel was approved and then rejected multiple times. I became unsure if my travel was approved or not and if I needed to do anything to help with the process.\n\n\n\n\n\n\n\nMultiple approval and rejection travel emails\n\n\n\nHi everyone,\nThis is the fifth email I’ve received today concerning my upcoming trip for the workshop. I’m reaching out because I am confused about the approval status of my trip. [punchline]\nIt appears that my trip is being approved and then rejected (at least twice?), leaving me unsure about the necessary steps to address this situation. [outstanding items]\nCould someone please provide clarification on what actions I should take to facilitate this process? [next steps]\nClaire",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Written and Verbal Communication</span>"
    ]
  },
  {
    "objectID": "02_written-verbal-communication.html#other-email-ettiquette-tips",
    "href": "02_written-verbal-communication.html#other-email-ettiquette-tips",
    "title": "3  Written and Verbal Communication",
    "section": "3.4 Other email ettiquette tips",
    "text": "3.4 Other email ettiquette tips\nMy vice president recently shared this blog by Fred Wilson on general tips for a “less is more” strategy for emails. These tips cover many of the points we’ve already discussed, but it’s good to read or hear them more than once to solidify the ideas.\n\n\n\n\n\n\nFigure 3.7: Cat typing on a laptop keyboard.\n\n\n\nThe header and the quoted text right after are content from the blog. I added some examples from my work emails.\n\n3.4.1 Be Concise\n\nDo you like getting long emails? No? No one does. A good rule of thumb is to strive to keep emails to one line or less. If they can’t be that short, challenge yourself to keep them as concise as humanly possible. Your contact is likely to be checking the message on a smartphone as on a desktop computer, or receiving many emails and in-person requests a day. Shorter is easier to digest – which means you’re more likely to get a response.\n\nBeing concise is part of Glickman (2011)’s three C’s:\n\nBe concise. No one likes to read a one-page email or listen to four-minute voice mail if he/she/they doesn’t have to. Be short and sweet, and to the point.\nBe clear. Don’t jump around topics or make people guess at your meaning or intentions. Clearly state your position, give the info you need to share, get the buy-in of your audience (if necessary), and move on.\nBe consistent. Using a consistent pattern to relay information will enable you to anticipate follow-up questions and/or think about missing pieces of information before giving someone an update-keeping you one step ahead of the curve.\n\n\n\n3.4.2 Communicate “action steps” first, not last\n\nIt’s standard practice to begin an email by summarizing what happened at a meeting or during a phone conversation, then following on with any “action steps” that emerged. But this makes it easy for the most important information to get lost in the shuffle. By reversing this order – and listing actions steps first and foremost – you keep the attention on the items you want to draw attention to.\n\n\n\n\n\n\n\nInvitation to join a new Research Coordination Network\n\n\n\nDear Claire,\nI am writing to you on behalf of the Future of Privacy Forum (FPF). Through a grant from the National Science Foundation (grant number 2413978), we are building a Research Coordination Network (RCN) dedicated to advancing the development, deployment, and practical application of Privacy Enhancing Technologies (PETs) to support socially beneficial data sharing and analytics.\nI wondered if you might have a few minutes to connect with me to discuss potential topics for the RCN and determine if you might be interested in participating yourself.\n[removed paragraphs about the proposed RCN]\nIf you do have a few moments, I would love to connect – I’d be happy to fit into your schedule and/or send you a link to book a time!\nThank you for considering this opportunity to shape the future of privacy and technology.\nChris\n\n\n\n\n3.4.3 Number your Questions\n\nThis is Email 101. If you’re not doing it already, it should be standard protocol to break out multiple points or questions as numbered items in all email correspondence. If you don’t, you risk having that customer or client only respond to the first question that happens to catch their eye. (And now you have to write another email to ask them about it again.)\n\n\n\n\n\n\n\nConference update\n\n\n\nHi all,\nThe planning committee is back with some updates/questions/comments to share.\nUpdates\n\nThe conference website is updated to include a schedule page, a registration page, and an updated support page. Please take a look and let us know if any updates are needed.\nWe recommend poster size of 36x48 and we are happy with whatever format the program committee decides on.\n\nQuestions\n\nAre you open to drop Day 2 roundtables and do a boxed lunch on Day 2 in case some attendees would need to catch a flight and leave early?\nDo we want to add a “closing (by co-chairs)” somewhere on Day 2 and if so when? The idea is to mostly make attendees stay till after lunch.\n\nIt would be good to finalize the conference schedule soon so that registered attendees can make travel plans, among other things.\nThanks and we look forward to hearing your thoughts on the above updates and questions. Have a wonderful weekend!\nBest,\nAva\n\n\n\n\n3.4.4 Make the way forward clear\n\nEmails that offer nothing but a “What do you think about X…?” are generally ineffectual. Always be proactive and take the lead in your communications so that the way forward is completely clear. If you’re proposing a deal, do a bullet‐pointed outline of the parameters from the get‐go. If you want to “run something by” a superior, share your approach and ask them if they agree. They may not, but giving them a starting point, something to react to, is MUCH more likely to get a response than waiting for someone else to make the first move.\n\n\n\n\n\n\n\nProject update and questions for next steps\n\n\n\nHi Kim,\nThank you for your patience. I intended to send you an update earlier this week, but when I returned from PTO, I found myself busier than anticipated.\nI reviewed the code book and data. To ensure we’re on the same page, I’ve drafted a document that outlines the synthesis project, detailing objectives for privacy and utility, along with expectations. Additionally, I’ve compiled a table of variables, their descriptions, and considerations for synthesis.\nIf possible, I would like for you to review this document to ensure that I have correctly captured the essential information regarding the project’s overarching goals and confirmed the correct subset of the data (which I believe pertains to the court cases).\nAlso, if you have any initial thoughts regarding synthesis considerations, please share them with me.\nClaire\n\n\n\n\n3.4.5 Include Deadlines\n\nSome people think that handing out deadlines can seem dictatorial. On the contrary, I’ve noticed that successful busy people welcome a deadline. It helps them integrate the tasks into their schedule. If a response from them is imperative, politely include a deadline: “For the project to stay on track, I need a response from you by 1/18.” If a response is optional, communicate that as well: “If I don’t hear back from you by 1/18, I’ll proceed with the solution I’ve proposed.”\n\n\n\n\n\n\n\nFinalizing a document\n\n\n\nHi Liam,\nI am ok pushing the release date for the document out further. However, Monday is Memorial day, so let’s aim for full release Tuesday, May 28.\nUpdated timeline below:\n\nWill and Ethan to review the remaining comments to ensure the changes didn’t change the meaning (EOD5, today, May 23).\nLiam to review the entire document (by noon, tomorrow, May 24).\nSophia to finalize copyedits and confirm edits (EOD, tomorrow, May 24).\nClaire and Liam to have the document on Urban Explorer and notify centers/divisions of the update (Tuesday, May 28).\n\nBox Link: LINK\nClaire\n\n\n\n\n\n\n\n\nImportant\n\n\n\nI often say, “Everyone loves a deadline,” because without a deadline, the next steps or action items after a meeting or discussion tend not to get completed.\n\n\n\n\n3.4.6 Use “FYI” for emails that have no actionable information\n\n(And if you’re already working on time-sensitive items with this contact, re-think sending non-actionable, less urgent information until end of day or even end of week).\n\n\nSome emails need to be shared to keep everyone in the loop. But non‐actionable correspondence should be labeled as such – so that it can be prioritized accordingly. Using a simple “FYI” tag at the top of all emails that contain information that you are not required to act on. It allows for easy filtering of non‐actionable emails, whether by scanning visually or setting up a rule in your email client. - (Also, recognize that if you’ve been working on high-priority items with this contact un-related to this non-actionable email, it might be best to save sending the “FYI” info email to later in the day.)\n\n\n\n\n\n\n\nA forwarded email about a proposal opportunity from the National Science Foundation\n\n\n\nRFS6 on AI7 dropped! Due May 10.\n\n\nAnd that’s all she (me) wrote!\n\n\n3.4.7 Tell them that you’ll get to it later\n\nIf someone sends you an urgent email that you can’t get to today (or this week, or month), write them a quick note and let them know, specifically when you will get to it. You’ll quell their anxiety, and save yourself a future nagging email from them. It also preserves goodwill: explaining now why you cannot get to something now is more effective than apologizing later.\n\n\n\n\n\n\n\nConfirming the presentation content\n\n\n\nHi Claire,\nCan this wait until Tuesday for an answer? I’d love to get Susan’s take on which approach she’d prefer you to take but she’s on leave until Tuesday.\nJames\n\n\n\n\n3.4.8 Use expressive and compelling subject lines.\n\nWe all skim our inboxes, deciding what to read now, and what to read later. The subject line is a key place to indicate importance and time sensitivity, using leaders like “FOR APPROVAL:” or “SCHEDULING REQUEST:” or “FYI:” to indicate what action is or is not needed. It’s useful to think of subject lines like newspaper (or blog) headlines – they should be expressive and compelling. It’s your prime chance to hook the reader in.\n\nExample headers in my inbox (outgoing and incoming):\n\nSummer 2024 DAN 607: Confirming Student Enrollment\nPlease approve by 05/28 2pm: Newsletter Blurb\nCONTRACT SIGNED 2/16/24, REF: 0219393.000, 003\nHOLD: SED Syn Focus Group\n\n\n\n3.4.9 Never send an angry or contentious email\n\nEmail is a severely limited medium when it comes to conveying tone, which is why angry emails are never a good idea. More often than not, they just create more anxiety – and more email. Occasionally, writing an angry email can be therapeutic. If this is the case, write it as a draft to get it off your chest, and then delete the email. When a confrontation is brewing, a conversation in person or on the phone is almost always best. Emails leave too much room for misunderstanding.\n\n\n\n\n\n\n\nFigure 3.8: Rick, from “Rick and Morty,” typing angerly.\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIf you are feeling annoyed or upset, delay sending the email. Type it, step away (or sleep on it if time allows), proofread, and then send.\n\n\n\n\n3.4.10 Never “reply all” (unless you absolutely must)\n\nIf you’ve received an email sent to a large group of people, do your best to avoid replying to all when you respond. If that person was qualified to send the email, typically they can be relied on to be the point person who collates the responses. Keep in mind: If using the “reply all” feature really seems necessary, you are probably having a conversation that would be better (and more efficiently) had face‐to‐face.\n\n\n\n\n\n\n\nDon’t pull a Dr. Lamere!\n\n\n\nShe accidentally hit reply all about ordering commencement regalia, and it was sent to all full time faculty, part time faculty, and bookstore email lists.\n\n\n\n\n\n\nFigure 3.9: Dr. Lamere’s reply all.",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Written and Verbal Communication</span>"
    ]
  },
  {
    "objectID": "02_written-verbal-communication.html#final-important-tips-and-activity",
    "href": "02_written-verbal-communication.html#final-important-tips-and-activity",
    "title": "3  Written and Verbal Communication",
    "section": "3.5 Final important tips and activity",
    "text": "3.5 Final important tips and activity\n\n3.5.1 Additional tips!\n\nAssume the other person has limited knowledge:\n\nSpell out acronyms.\nCarefully explain the situation, providing concise context, and/or be explicit on your reference (e.g., include a link to the referenced article).\n\nProofread written emails:\n\nTake a moment to review your email before sending to avoid simple mistakes like confusing “your” and “you’re”.\nMake sure to spell the person’s name correctly (or use their preferred name), especially if they use it in their signature in the previous email.\nConsider asking someone else to proofread, especially for sensitive topics where tone is crucial (and is often hard to convey via written communication).\n\nOpt for verbal conversations for sensitive topics:\n\nNuance and tone are better conveyed through verbal communication and can avoid miscommunication.\n\nMaintain professionalism in verbal or in-person interactions:\n\nRefrain from using profanity in professional settings.\nPractice your “poker face”, as some feelings like annoyance may inadvertently show, and people can tell.\n\nAvoid rambling during meetings:\n\nPause to collect thoughts, but avoid long-winded explanations that may frustrate others.\n\nSpeak up when relevant:\n\nContribute to discussions in meetings, but be thoughtful and concise on what you say.\n\nPhone calls for quick questions and discussions are your friend:\n\nFor brief questions or discussions, opt for a phone call to minimize miscommunication.\nMany people are uncomfortable talking to people they don’t know. It may be awkward the first few dozen times cold calling a random person, but practice makes perfect and you will find yourself to it!\n\n\n\n\n3.5.2 Practice and feedback\n\n\n\n\n\n\nClass Activity 4\n\n\n\nWrite an introduction email to me with information on what other non-technical professional skills you would like to learn during week 5 (June 21) class.\n\n\n\n\n\n\nGlickman, Jodi. 2011. Great on the Job: What to Say, How to Say It. The Secrets of Getting Ahead. St. Martin’s Griffin.",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Written and Verbal Communication</span>"
    ]
  },
  {
    "objectID": "02_written-verbal-communication.html#footnotes",
    "href": "02_written-verbal-communication.html#footnotes",
    "title": "3  Written and Verbal Communication",
    "section": "",
    "text": "Full-time equivalent.↩︎\nClose of business.↩︎\nThe Joint Statistical Meetings is the largest gathering of statisticians in the world and hosted in North America.↩︎\nNational Science Foundation National Center for Science and Engineering Statistics.↩︎\nEnd of day.↩︎\nRequest for solutions.↩︎\nArtificial intelligence.↩︎",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Written and Verbal Communication</span>"
    ]
  },
  {
    "objectID": "02_data-collection.html",
    "href": "02_data-collection.html",
    "title": "4  Data Collection and Acquitition",
    "section": "",
    "text": "4.1 Data types\nThere are generally three principal types of qualitative and quantitative data:",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Collection and Acquitition</span>"
    ]
  },
  {
    "objectID": "02_data-collection.html#data-types",
    "href": "02_data-collection.html#data-types",
    "title": "4  Data Collection and Acquitition",
    "section": "",
    "text": "Primary: Any data directly collected by an entity.\nSecondary: Any data collected by another organization that a stakeholder uses for analysis.\nAdministrative: Any data collected by governments or other organizations, as part of their management and operation of a program or service, that provide information on registrations, transactions, and other regular tasks.\n\n\n4.1.1 Primary data\nDirect data collection includes both quantitative data (e.g., from a survey) and qualitative data (e.g., from focus groups, site visits, qualitative interviews, or trained observations) collected from individuals or organizations. Also, with primary you will usually have access to paradata.1\n\n\n4.1.2 Secondary data\nSecondary data also include both quantitative and qualitative data; depending on the source, they may also include some paradata. Often, secondary data are in public-use files that have been sanitized for general release and use (e.g., public file of the American Community Survey2).\n\n\n4.1.3 Administrative data\nAdministrative data are collected for the administration of an organization or program by entities, such as government agencies as they provide services, companies to track orders, and universities to record registered students. These data records are usually not public-use data files and tend to only be accessed through strict confidentiality agreements, such as non-disclosure agreements or memorandum of understanding (e.g., IRS tax payer data).\n\n\n\n\n\n\nClass Activity 1\n\n\n\nFor each data type:\n\nWhat are some other examples?\nWhat are the possible security, privacy, ethical, and equity considerations and challenges?\nIf these challenges are not addressed, what are the potential downstream impact?",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Collection and Acquitition</span>"
    ]
  },
  {
    "objectID": "02_data-collection.html#discussion-on-do-no-harm-guide-collecting-analyzing-and-reporting-gender-and-sexual-orientation-data",
    "href": "02_data-collection.html#discussion-on-do-no-harm-guide-collecting-analyzing-and-reporting-gender-and-sexual-orientation-data",
    "title": "4  Data Collection and Acquitition",
    "section": "4.2 Discussion on Do No Harm Guide: Collecting, Analyzing, and Reporting Gender and Sexual Orientation Data",
    "text": "4.2 Discussion on Do No Harm Guide: Collecting, Analyzing, and Reporting Gender and Sexual Orientation Data\n\nIf equity isn’t considered in the design of the study for that small subgroup, then it’s not the main purpose of the study. Other parts will take priority. Afterall, what was the study designed for?\n\n~ Saki Kinney, RTI (Research Triangle International)\nThis quote from a colleague highlights the importance of how data is collected. If we blindly collect data without careful consideration of the process—such as how we define groups or the methods used for data collection—we could severely and negatively impact those groups when others in the data ecosystem use and analyze that data.\nThe required reading assignment, Do No Harm Guide (DNHG) by Schwabish et al. (2023), covers many data collection challenges and will facilitate our discussion on the potential security, privacy, ethical, and equity issues in data collection.\n\n\n\n\n\n\nFigure 4.1: The cover of the Urban Institute report, “Do No Harm Guide: Collecting, Analyzing, and Reporting Gender and Sexual Orientation Data .”\n\n\n\n\n4.2.1 Defining groups is important\n\nCollecting data about sexual orientation and gender identity and expression allows for a better understanding of sexual and gender minority populations, enabling researchers, policymakers, and advocates to understand differences between these populations and other population groups or the general population across policy areas. Insight from these data highlight important areas for interventions that may improve the lives of members of sexual and gender minority groups.\n\n\n\n\n\n\n\nClass Activity 2\n\n\n\nThere is a glossary at the start of the DNHG instead of at the end.\n\nWhy do you think the authors had the glossary so early in the report?\nDo you think the government, schools, or other organizations that collect data use the same definition when collecting data?\nWhat is the impact of not having a standard definition for each stakeholder in the data ecosystem?\n\n\n\n\n\n4.2.2 Trans-parency in the legal community\nThe American Bar Association wants to release more demographic information about students who attend law school and complete the bar exam. One piece of information they want to share is the number of transgender students attending their law schools. Some students support this decision, believing it will allow other transgender students to reach out to them or see that the law school is welcoming toward transgender students. Others, however, want this information to be withheld for safety reasons, preferring that their law programs do not disclose that they have transgender students.\n\n\n\n\n\n\nClass Activity 3\n\n\n\nIn this scenario, how would you answer the following:\n\nUser engagement is emphasized in the DNHG. Who would you try to engage in a conversation about collecting and releasing information about transgender students in law school?\nWhat are your thoughts if the decision is to collect the data, but the outcome is not to release the information?\nWhat are the security, privacy, ethics, and equity considerations when deciding to collect and/or release the information?\n\n\n\nInstitutional Review Boards (IRBs) review an institution’s (e.g., university, government agency) research, evaluation, and technical assistance projects involving information collected from or about human subjects. The IRB reviews projects’ data collection procedures and data security plans with the objective of protecting the rights and welfare of human subjects and minimizing risks to them, as mandated by federal regulations and consistent with longstanding institutional policies.\n\n\n\n\n\n\nThe importance of IRB\n\n\n\nAny university or research institution-led survey or data collection involving human subjects must undergo an Institutional Review Board (IRB) process. If you see someone conducting a survey without information about the security, privacy, and confidentiality of the data, including its use, storage, and termination, you must report it to the university’s or research institution’s IRB.\n\n\n\n\n4.2.3 How do we define ourselves and society\n\nThere are two sides to survey data collection: the experience of the participant and the experience of the researcher. Thus, building trust between the participant and the researcher is key to generating high-quality data. Communicating to people why their personal information is necessary and gaining their formal consent can lead to greater collaboration and, ultimately, allow for more inclusive survey methods.\n\nPart 3 of the DNHG reviews various methods for conducting surveys to collect sexual orientation and gender identity information. This highlights the challenge of properly defining groups in a way that is both consistent and inclusive.\n\n\n\n\n\n\nClass Activity 4\n\n\n\nArticle I, Section 2 of the Constitution mandates that a census must take place every 10 years in the United States. The data collected by the decennial census determine the number of seats each state has in the U.S. House of Representatives and how to distribute the trillions in federal funds to local communities.\nAs part of the decennial census, people must answer several questions, such as what is their race. How would define your race?\nThe images below show the race question for the 1990 and 2020 Census questionnaire. Would your definition match what is offered in these questionnaires?\n\n\n\n\n\n\n\n\nFigure 4.2: 1990 Census Race Question\n\n\n\n\n\n\n\n\n\nFigure 4.3: 2020 Census Race Question\n\n\n\nThe nuances of different races is important in some contexts and not in others. For example, the state of Wyoming probably only needs to know the number of Asian Americans (i.e., coarsen all subgroups into the larger group), whereas New York City needs the count of various subgroups, because each subgroup has different poverty rates (Sonoda and Hahn 2023).",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Collection and Acquitition</span>"
    ]
  },
  {
    "objectID": "02_data-collection.html#no-data-no-problem-no-action",
    "href": "02_data-collection.html#no-data-no-problem-no-action",
    "title": "4  Data Collection and Acquitition",
    "section": "4.3 No data, no problem, no action",
    "text": "4.3 No data, no problem, no action\nWe will cover two real-world example sets where the lack of data or improper data collection negatively impacts downstream data analysis.\n\n4.3.1 Library of Missing Datasets\nDo you agree or disagree that we should answer the following questions with data?\n\nSales and prices in the art world (and relationships between artists and gallerists)\nPeople excluded from public housing because of criminal records\nTrans people killed or injured in instances of hate crime (note: existing records are notably unreliable or incomplete)\nPoverty and employment statistics that include people who are behind bars\nMuslim mosques/communities surveilled by the FBI/CIA\nMobility for older adults with physical disabilities or cognitive impairments\nLGBT older adults discriminated against in housing\nUndocumented immigrants currently incarcerated and/or underpaid\nUndocumented immigrants for whom prosecutorial discretion has been used to justify release or general punishment\nMeasurements for global web users that take into account shared devices and VPNs\nFirm statistics on how often police arrest women for making false rape reports\nMaster database that details if/which Americans are registered to vote in multiple states\nTotal number of local and state police departments using stingray phone trackers (IMSI-catchers)\nHow much Spotify pays each of its artists per play of song\n\nWhat if you were then told that there are no such datasets created or available to answer these questions?\n\n\n\n\n\n\nFigure 4.4: The image from Mimi Ọnụọha’s The Library of Missing Datasets 3.0\n\n\n\nThese questions are part of a mixed-media installation by Mimi Ọnụọha called, The Library of Missing Datasets, which is on version 3.0. This piece is a physical repository of those things that have been excluded in a society where so much is collected.\nFrom Mimi Onuoha’s website,\n\n“Missing datasets” are the blank spots that exist in spaces that are otherwise data-saturated. Wherever large amounts of data are collected, there are often empty spaces where no data live. The word “missing” is inherently normative. It implies both a lack and an ought: something does not exist, but it should. That which should be somewhere is not in its expected place; an established system is disrupted by distinct absence. That which we ignore reveals more than what we give our attention to. It’s in these things that we find cultural and colloquial hints of what is deemed important. Spots that we’ve left blank reveal our hidden social biases and indifferences.\n\n\n\n\n\n\n\nClass Activity 5\n\n\n\nMimi Ọnụọha created the list of questions for “The Library of Missing Datasets 3.0” in 2022. Her GitHub repo indicates that one of the illustrative examples from her version 2 installation in 2018 is no longer missing.\n\nCivilians killed in encounters with police or law enforcement agencies [update: this is no longer a missing dataset]\n\nIn the next 10 to 15 minutes, pick one of the example questions from the “Library of Missing Datasets 3.0” and try to find a publicly available dataset that answers that question.\nDid you find a dataset that works? If not, did you find a dataset that was close? Why did the dataset not answer the question?\n\n\nMimi Ọnụọha says there are many reasons why some potentially important datasets are missing and highlights four reasons:\n\nThose who have the resources to collect data lack the incentive to (corollary: often those who have access to a dataset are the same ones who have the ability to remove, hide, or obscure it).\n\n\nPolice brutality towards civilians provides a powerful example. Though policing and crime are among the most data-driven areas of public policy, traditionally there has been little history of standardized and rigorous data collected about police brutality. Nowadays we have a political and cultural climate where this issue has become one of public discussion. Public interest campaigns like Fatal Encounters and the Guardian’s The Counted have helped fill that void. But even for these individuals/organizations, the work is difficult and time-consuming. The group who would make the most sense to monitor this issue—the law enforcement agents who create the data set in the first place—have no incentive to actually gather such data, which could prove incriminating.\n\n\nThe data to be collected resist simple quantification (corollary: we prioritize collecting things that fit our modes of collection).\n\n\nThe defining tension of data collection is the struggle of taking a messy, organic world and defining it in formats that are neat, clean, and structured. Some things are difficult to collect and quantify by nature of their structure. We don’t know how much US currency is outside of our borders. There’s no incentive for other countries to monitor US currency within their countries, and the very nature of cash and the anonymity it affords makes it difficult to track. But then there are other subjects that resist quantification entirely. Things like emotions are hard to quantify (at this time, at least). Institutional racism is subtle and deniable; it reveals itself more in effects than acts. Not all things are easily quantifiable, and at times the very desire to render the world more abstract, trackable, and machine-readable is an idea that itself deserves questioning.\n\n\nThe act of collection involves more work than the benefit the presence of the data is perceived to give.\n\n\nSexual assault and harassment are woefully underreported. And while there are many reasons why this is, one major one is that in many cases the very act of reporting sexual assault is a very intensive, painful, and difficult process. For some, the benefit of reporting isn’t perceived to be equal or greater than the cost of the process.\n\n\nThere are advantages to nonexistence.\n\n\nEvery missing dataset is a testament to this fact. Just as the presence of data benefits someone, so too does the absence. This is important to keep in mind. However, there’s an even more specific angle to this point. To collect, record, and archive aspects of the world is an intentional act, one that typically benefits those who have the power to decide what should be collected. Often, remaining outside of the bounds of collection can be a form of response for a situationally-disadvantaged group. In short, sometimes a missing dataset can function as a form of protection.\n\n\n\n\n\n\n\nClass Activity 6\n\n\n\nIf you could not find a dataset, why do you think that dataset doesn’t exist based on the four reasons Mimi Ọnụọha highlighted?\n\n\n\n\n4.3.2 Asian Americans are highly educated, born in the U.S., and speak English\nNot collecting data is one issue. Another, which could be just as or even more detrimental to society, is collecting the wrong kind of data. If we are not careful with how we design data collection, we could create harmful narratives about certain areas of society, especially underrepresented groups.\nAn example of this is work done by my colleague, Dr. Sunghee Lee of the University of Michigan. She presented her in the same conference session as me, where she discussed how incomplete data on Asian-American populations risks fueling a vicious circle of inaction and growing inequality. One of her projects compared the socio-demographics of Asian-American respondents reported in four large-scale sample surveys against the same characteristics collected by the US Census Bureau’s American Community Survey,3 which is often referred to as the gold standard survey on the United States populations and housing information (Tarran 2023).\nWhen comparing these surveys, Dr. Lee found that the four surveys often differed in important respects. For example, Asian Americans accounted for seven percent of adults aged 18 and over in the American Community Survey. In contrast, the General Social Survey4 and Behavioral Risk Factor Surveillance Survey5 accounted for only four percent and two percent, respectively. The American Community Survey shows 27 percent of Asian-American respondents are educated to high-school level or below, the equivalent grouping in the Behavioral Risk Factor Surveillance Survey accounted for 18 percent.\nHowever, none of these surveys, except the American Community Survey, collected data on Asian Americans’ proficiency with spoken English.\nAccording to the American Community Survey, 31 percent of Asian-American adults have “limited English proficiency.” Dr. Lee’s research found that none of the four selected surveys (General Social Survey and Behavioral Risk Factor Surveillance Survey, plus the Current Population Survey6 and National Health Interview Survey7) offered questionnaires in Asian languages; only English and Spanish.\nDue to the poorly designed surveys, anyone using these data will find that most Asian Americans are born in the US and/or who have high levels of English proficiency, missing the true geographic and ethnic heterogeneity of the Asian American population. This underrepresentation of certain Asian-American subgroups encourages a potential vicious cycle of having no “data-driven” proof to collect such information. This means that issues affecting certain population groups are not identified, meaning no action needs to be taken.\nHence, at the end of the presentation, Dr. Lee’s slide stated, “No data, no problem, no action”.\n\n\n\n\n\n\nFigure 4.5: Roll Safe Think About It meme that says, “Can’t have any issues, if there is no data.”\n\n\n\n\n\n\n\n\n\nClass Activity 7\n\n\n\nAfter learning about this use case, answer the following:\n\nWhat is your reaction to this situation?\nCan you think of other situations where a lack of data would lead to no action because no one knows there is a problem?",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Collection and Acquitition</span>"
    ]
  },
  {
    "objectID": "02_data-collection.html#week-3-assignment",
    "href": "02_data-collection.html#week-3-assignment",
    "title": "4  Data Collection and Acquitition",
    "section": "4.4 Week 3 Assignment",
    "text": "4.4 Week 3 Assignment\n\n\n\n\n\n\nDEADLINE\n\n\n\nDue June 6, at 11:59 PM EDT on Canvas\n\n\n\n4.4.1 Read\n\nChapter 3: How Do Data Privacy Methods Expand Access to Data?\n\n\n\n4.4.2 Optional additional read\n\nDo No Harm Guide: Applying Equity Awareness in Data Privacy Methods.\n\n\n\n4.4.3 Write (600 to 1200 words)\nWe learned that one way to define data equity in the context of privacy is to consider equal privacy loss or equal access for different subgroups. Answer the following questions:\n\nDo you agree that these are helpful ways to define equity in the context of privacy?\nAre there additional ways you would define equity in the context of privacy?\nAre there other equity considerations to take into account?\nWhat are the ethical implications of defining equity in the context of privacy in these ways?\n\n\n\n\n\nSchwabish, Jonathan, Donovan Harvey, Mel Langness, Vincent Pancini, Amy Rogin, and Gabi Velasco. 2023. “Do No Harm Guide: Collecting, Analyzing, and Reporting Gender and Sexual Orientation Data.”\n\n\nSonoda, Paige, and Heather Hahn. 2023. “Disaggregating Data Is Critical to Dismantling the Model Minority Stereotype.” https://www.urban.org/urban-wire/disaggregating-data-critical-dismantling-model-minority-stereotype.\n\n\nTarran, Brian. 2023. “JSM Session Touches on Equity.” Amstat News. https://magazine.amstat.org/blog/2023/11/01/jedi-corner-jsm-session-equity/.",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Collection and Acquitition</span>"
    ]
  },
  {
    "objectID": "02_data-collection.html#footnotes",
    "href": "02_data-collection.html#footnotes",
    "title": "4  Data Collection and Acquitition",
    "section": "",
    "text": "Paradata are a by-product of data collection. Types of paradata vary from contact attempt history records for interviewer-assisted operations, to form tracing using tracking numbers in mail surveys, to keystroke or mouse-click history for internet self-response surveys. Because paradata are a by-product of a given data collection operation, their format, layout, and content are a function of the system that generated the data.↩︎\n“The American Community Survey helps local officials, community leaders, and businesses understand the changes taking place in their communities. It is the premier source for detailed population and housing information about our nation.” U.S. Census Bureau’s page on the American Community Survey.↩︎\n“The American Community Survey helps local officials, community leaders, and businesses understand the changes taking place in their communities. It is the premier source for detailed population and housing information about our nation.” U.S. Census Bureau’s page on the American Community Survey.↩︎\n“[C]onducted every two years, NORC interviews a representative sample of Americans about a range of topics. The questions address belief in God, confidence in government institutions, race relations, abortion, spending patterns, gun rights, social isolation—even pet ownership.” NORC at the University of Chicago’s page on the General Social Survey.↩︎\n“The Behavioral Risk Factor Surveillance System (BRFSS) is the nation’s premier system of health-related telephone surveys that collect state data about U.S. residents regarding their health-related risk behaviors, chronic health conditions, and use of preventive services.” U.S. Centers for Disease Control and Prevention’s page on the Behavioral Risk Factor Surveillance System.↩︎\n“The Current Population Survey, sponsored jointly by the U.S. Census Bureau and the U.S. Bureau of Labor Statistics, is the primary source of labor force statistics for the population of the United States.” U.S. Census Bureau’s page on the Current Population Survey.↩︎\n“The National Health Interview Survey on a broad range of health topics are collected through personal household interviews. Survey results have been instrumental in providing data to track health status, health care access, and progress toward achieving national health objectives.” U.S. Centers for Disease Control and Prevention’s page on the National Health Interview Survey.↩︎",
    "crumbs": [
      "Introduction and Data Collection",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Collection and Acquitition</span>"
    ]
  },
  {
    "objectID": "03_data-storage.html",
    "href": "03_data-storage.html",
    "title": "5  Data Storage",
    "section": "",
    "text": "5.1 Quick recap on week 2\nWe should consider the interactions within this ecosystem and the data life cycle in the context of security, privacy, ethics, and equity.",
    "crumbs": [
      "Data Storage and Sharing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Storage</span>"
    ]
  },
  {
    "objectID": "03_data-storage.html#quick-recap-on-week-2",
    "href": "03_data-storage.html#quick-recap-on-week-2",
    "title": "5  Data Storage",
    "section": "",
    "text": "5.1.1 Definitions\n\n\n\n\n\n\nFigure 5.1: Key stakeholders in the data ecosystem\n\n\n\n\n\n\n\n\n\nData Security\n\n\n\nData Security is the “…science of methods of protecting computer data and communication systems that apply various types of controls such as cryptography, access control, information flow paths and inference control, including backup and recover” (Denning 1982).\n\n\n\n\n\n\n\n\nData Privacy\n\n\n\nData Privacy is the ability “to determine what information about ourselves we will share with others” (Fellegi 1972). Data privacy is a broad topic, which includes data security, encryption, access to data, etc. We will not be covering privacy breaches from unauthorized access to a database (e.g., hackers).\n\n\n\n\n\n\n\n\nConfidentiality\n\n\n\nConfidentiality is “the agreement, explicit or implicit, between data subject and data collector regarding the extent to which access by others to personal information is allowed” (Fienberg and Jin 2018).\n\n\n\nHackers: adversaries who steal confidential information through unauthorized access.\nSnoopers: adversaries who reconstruct confidential information from data releases.\nHoarders: stewards who collect data but don’t release the data even if respondents want the information releasesd.\n\n\n\n\n\n\n\nEthics\n\n\n\nData ethics is the “…systemizing, defending, and recommending concepts of right and wrong conduct in relation to data, in particular personal data” (Kitchin 2014).\n\n\n\n\n\n\n\n\nEquity\n\n\n\nData Equity is data representation, access, process, outcomes, and more.\n\n\n\n\n5.1.2 Data types\nWe learned about the three principal types of qualitative and quantitative data:\n\nPrimary: Any data directly collected by an entity.\nSecondary: Any data collected by another organization that a stakeholder uses for analysis.\nAdministrative: Any data collected by governments or other organizations, as part of their management and operation of a program or service, that provide information on registrations, transactions, and other regular tasks.\n\n\n\n5.1.3 Data collections challenges\nWe’ve discussed several challenges surrounding security, privacy, ethics, and equity in data collection. Specifically, we’ve highlighted the importance of:\n\nDeciding whether to collect the data or not.\nDefining groups and other variables that impacts our communities.\nRecognizing that a lack of data results in a lack of action.",
    "crumbs": [
      "Data Storage and Sharing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Storage</span>"
    ]
  },
  {
    "objectID": "03_data-storage.html#why-is-data-storage-so-important",
    "href": "03_data-storage.html#why-is-data-storage-so-important",
    "title": "5  Data Storage",
    "section": "5.2 Why is data storage so important?",
    "text": "5.2 Why is data storage so important?\n\nArchives and domain repositories that preserve and disseminate social and behavioral data perform a critical service to the scholarly community and to society at large by ensuring that these culturally significant materials are accessible in perpetuity. The success of the archiving endeavor, however, ultimately depends on researchers’ willingness to deposit their data and documentation for others to use.\n\nFrom Inter-university Consortium for Political and Social Research (ICPSR, n.d.), one of the world’s largest data archives of social science data for research and education.\n\n5.2.1 More definitions\nThere are many versions of the data we should define.\n\n\n\n\n\n\nOriginal dataset:\n\n\n\nOriginal dataset is the uncleaned, unprotected version of the data.\nFor example, raw 2020 Decennial Census microdata, which are never publicly released.\n\n\n\n\n\n\n\n\nConfidential or gold standard dataset\n\n\n\nConfidential or gold standard dataset is the cleaned version (meaning edited for inaccuracies or inconsistencies) of the data; often referred to as the gold standard or actual data for analysis.\nFor example, the Census Edited File that is the final confidential data for the 2020 Census. This dataset is never publicly released but may be made available to others who are sworn to protect confidentiality (i.e., Special Sworn Status) and who are provided access in a secure environment, such as a Federal Statistical Research Data Center.\n\n\n\n\n\n\n\n\nPublic dataset or statistics\n\n\n\nPublic dataset is the publicly released version of the confidential data.\nFor example, the US Census Bureau’s public tables and datasets or the Bureau of Labor Statistics reporting the unemployment rate statistics.\n\n\nDifferent levels of security and privacy are needed for different versions of the data. We will mostly focus on the confidential and public versions of the data. However, note that the original or raw data must also be securely stored and properly documented for future reference.\n\n\n\n\n\n\nNo set taxonomony in the field!\n\n\n\nAll definitions used (including the data life cycle) are my opinionated definitions. Since many different fields work in data security, privacy, ethics, and equity, there is no standard taxonomy, which causes a lot of confusion. I set a standard definition in all my work, including this course, to ensure we are using the same common language. However, note that when reading other materials or literature, you might encounter conflicting terminology.\n\n\n\n\n5.2.2 Data cleaning\nAfter data collection, the data curator will usually need to clean the raw data, which are often messy, inconsistent, and contain missing values, among other issues. For most projects, cleaning the data takes up the majority of the time in any data project from start (data collection) to finish (data dissemination and/or destruction). This important task converts the data into a usable form for others.\n“Tidy data” tends to have the following features:\n\nEach variable forms a column.\nEach observation forms a row.\nEach type of observational unit forms a dataframe.\n\n\n\n\n\n\n\nFigure 5.2: Artwork by Allison Horst.\n\n\n\nGiven the conceptual focus of the course, we will not be doing any exercises involving data cleaning using code. Instead, we will cover the important considerations for data cleaning if you are ever tasked with it.\nEveryone has their own method for cleaning data, and you will find several sources with different steps to follow. However, these various sources generally share a similar set of steps or aspects to check for when cleaning data, which we will discuss.\n\n\n\n\n\n\nCreate backups!\n\n\n\nAlways make a backup copy of the original data prior to cleaning it just in case something happens!\n\n\n\nCheck for data quality issues\nCommon issues include duplicate observations or records, spelling errors, incorrect numbers and number signs, and inconsistencies where the sum doesn’t equal the total (e.g., the number of people in each county of Massachusetts should equal the state total).\n\n\n\n\n\n\nCareful about outliers\n\n\n\nSome people suggest removing outliers, but you should be very careful about this practice. The outlier may be a true signal of something happening in your data. Proceed with caution when deciding to remove observations or values in the data if they are outliers.\n\n\n\n\nStandardize the data\nThis involves changing text case, removing spaces and non-printing characters from text, fixing dates and times (a HUGE issue!), and ensuring consistent units across variables.\n\n\nDefine how to handle missing data\nMissing data can significantly impact downstream uses of the data. Clearly document how you handled missing data. Options include removing the records or imputing the missing values using a statistical technique.\n\n\nValidate the data cleaning (Quality assurance)\nAlways validate or conduct a quality assurance procedure to ensure you have taken the proper steps to clean the data.\n\n\n\n5.2.3 Educational attainment example\nSuppose a researcher gathers data from various participants who have filled out a form about educational attainment. The raw data might look something like this:\n\n\n\nFictious dataset of educational attainment.\n\n\nName\nRace\nAge\nEducation\n\n\n\n\npeter hunter\ncaucasian\n25\nbachelors\n\n\nBeth SMITH\nafrican-american\n32\nMaster’s\n\n\nryan chadwick\nCaucasian\n40\nPHD\n\n\nSilvia Li\nasian\n28\nbachelors\n\n\nLarry Thomas\nasian\ntwenty-three\nhigh school diploma\n\n\nAnne-Marie\ncaucasian\n35\nBachelor’s\n\n\n\n\n\n\n\n\n\n\n\nClass Activity 1\n\n\n\nBased on the initial data collection of this raw data, answer the following (2 minutes):\n\nWhat are some issues with the data?\nWhat steps you would take to clean the data?\n\n\n\n\n\n\n\n\n\nPossible issues\n\n\n\n\n\n\nInconsistent Name Formats: Variations in capitalization and punctuation.\nInconsistent Race Descriptions: Different spellings and capitalizations.\nInconsistent Age Formats: Numeric and word formats.\nInconsistent Education Levels: Variations in capitalization and abbreviations.\n\n\n\n\n\n\n\n\n\n\nPossible cleaning steps\n\n\n\n\n\n\nStandardizing Name Formats:\n\nCapitalize all names properly.\nCorrect: “John Doe” instead of “john doe”.\n\nStandardizing Race Descriptions:\n\nEnsure race descriptions are consistent.\nCorrect: “African-American” instead of “african-american”.\n\nStandardizing Age Formats:\n\nConvert all ages to numeric format.\nCorrect: “23” instead of “twenty-three”.\n\nStandardizing Education Levels:\n\nUse consistent terms and capitalizations.\nCorrect: “Bachelor’s” instead of “bachelors” and “Ph.D.” instead of “PHD”.\n\n\n\n\n\n\n\n\nCleaned version of the fictious data.\n\n\nName\nRace\nAge\nEducation\n\n\n\n\nPeter Hunter\nCaucasian\n25\nBachelor’s\n\n\nBeth Smith\nAfrican-American\n32\nMaster’s\n\n\nRyan Chadwick\nCaucasian\n40\nPh.D.\n\n\nSilvia Li\nAsian\n28\nBachelor’s\n\n\nLarry Thomas\nAsian\n23\nHigh School Diploma\n\n\nAnne-Marie\nCaucasian\n35\nBachelor’s\n\n\n\n\n\n\n\n\n\n\n\nClass Activity 2\n\n\n\nThere is still one potential issue with the data. What is it and can anything be done?\n\n\n\n\n\n\n\n\nCognitive testing and questionnaire evaluation\n\n\n\nPrior to launching a survey, most entities should conduct cognitive interviews1 and other survey evaulations to ensure the surveys are easy to understand (avoiding misinterpretations of the questions), can be completed within the suggested time frame, and capture the correct information, among other things.\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.2.4 Credit data\nSuppose you have credit bureau data, which is rich in information but lacking details on race and ethnicity. Including this information would be beneficial, as there are documented cases of how credit scores affect racial homeownership gaps (Choi et al. 2019) and how credit screens impact hiring (Traub and McElwee 2016). A team member suggests using imputation, a method for generating missing values, to infer race and ethnicity based on name, age, and location (ZIP code).\n\n\n\n\n\n\nClass Activity 3\n\n\n\nWhat are your thoughts on this scenario and approach to create race and ethnicity (2 minutes)?\n\n\n\n\n\n\n\n\nOpen only after discussion\n\n\n\n\n\n\nThe most widely used method for imputing race and ethnicity on administrative data is Bayesian Improved Surname Geocoding, which the RAND Corporation developed for the US Department of Health and Human Services and which is also used by the Equal Opportunity Employment Commission and the Consumer Financial Protection Bureau (CFPB). The latest method involving this tool, Medicare Bayesian Improved Surname Geocoding 2.0, combines name, administrative data, and census data based on address in a calibrated Bayesian framework (a multinomial logistic regression model) to estimate probabilities by race and ethnicity for each record in a dataset.\n\nFrom Stern and Narayanan (2021), where they tested Bayesian Improved Surname Geocoding to learn from a case study in an attempt to incorporate equity in imputing race and ethnicity onto a nationally representative sample of credit bureau data.",
    "crumbs": [
      "Data Storage and Sharing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Storage</span>"
    ]
  },
  {
    "objectID": "03_data-storage.html#data-security-basics",
    "href": "03_data-storage.html#data-security-basics",
    "title": "5  Data Storage",
    "section": "5.3 Data security basics",
    "text": "5.3 Data security basics\n\nThe only system which is truly secure is one which is switched off and unplugged locked in a titanium lined safe, buried in a concrete bunker, and is surrounded by nerve gas and very highly paid armed guards. Even then, I wouldn’t stake my life on it.\n\n~ Gene Spafford, Director, Computer Operations, Audit, and Security Technology (COAST) Project, Purdue University\nFor all data, you should indicate how and where you will store copies of your research files to ensure their safety, as well as how many copies you will keep and how you will synchronize them (You do NOT want multiple versions of one data floating around!).\nOnce figuring out how to synchronize them, one best practice for protecting data is to store multiple copies in multiple locations. How and where you store the data depends on the contents of the data, privacy laws in place, your workplace practices, any contractual agreements, and other factors. We will touch on a few of these issues today and in future classes, but know there are many others, and you should always consult with the data security officer of your institution or workplace.\n\n5.3.1 Virtual data storage\n\n\n\n\n\n\nFigure 5.3: One Does Not Simply meme from the movie,“Lord of the Rings,” that says, “One Does not Simply Walk Awary and Leave your Computer Unlocked.”\n\n\n\nMost universities, privacy companies, government agencies, and other places will maintain confidential disks separate from nonconfidential disks for their system servers. Any confidential data stored on disks should have some sort of encryption system, such as Pretty Good Privacy2, at the folder level.\nIf someone uses an account or a computer with access to confidential data, they must not leave the session unattended, must log out at the end of the session, and must lock up any storage media that hold confidential data.\nOther good data security practices include:\n\nlimiting access to confidential data to authorized users, such as through a secure login\nmultiple levels of encryption\nprevention of individuals making copies of the confidential data to nonconfidential disks (or copying the data at all)\nvirus and intruder protections\n\n\n\n5.3.2 Physical data storage\n\n\n\n\n\n\nFigure 5.4: A scene from the TV Show, “Futurama,” with the character Leela is trying to hide papers. The text says, “Too much papers! Not enough hiding plants!\n\n\n\nIf confidential data are stored on a PC, the data should be encrypted or stored on removable storage media that is secured in a locked cabinet when not in use.\nAll storage media (e.g., CDs, internal and external hard drives, flash drives) that hold confidential data must be explicitly labeled “confidential.” The project security officer or project manager (depends on your workplace) should maintain a log for each piece of confidential storage media and record dates for the following:\n\nreceipt of the item from external source\ncreation of the item at the institution\ndestruction of the item\ntransfer of the item to someone else’s responsibility (even within the institution)\n\n\n\n\n\n\n\nSecurity and privacy trainings and audits\n\n\n\nFrequently, the workplace and/or entities allowing data use must participate in annual training sessions on the appropriate handling of confidential data. Additionally, they conduct semiannual reviews of confidential logs to ensure that all confidential media is properly accounted for.",
    "crumbs": [
      "Data Storage and Sharing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Storage</span>"
    ]
  },
  {
    "objectID": "03_data-storage.html#importance-of-meta-data",
    "href": "03_data-storage.html#importance-of-meta-data",
    "title": "5  Data Storage",
    "section": "5.4 Importance of meta data",
    "text": "5.4 Importance of meta data\n\nMetadata are essential for maximizing the usefulness of data. Because it is often impossible for secondary researchers to ask questions of the original data producers, metadata are the de facto form of communication between them. Comprehensive metadata standardizes how the data are described, enables a deeper comprehension of a dataset, facilitates data searches by variables, and offers a variety of display options on the Web.\n\n\n\n\n\n\n\nMeta data\n\n\n\nMetadata is “information about the data collections that help others discover, understand, and use them.”\nFrom ICPSR’s webpage on Metadata.\n\n\nThe lack of metadata across public datasets from local, state, territory, tribal, and federal government agencies is one reason why the The Open, Public, Electronic and Necessary (OPEN) Government Data Act was included as a section in the 2018 Foundations for Evidence-Based Policymaking Act, a bipartisan U.S. law pushing the federal government to modernize the data infrastructure, such as data management, statistical efficiency, and more.\nTo help conceptually understand what kind of information should be a part of meta data, we will follow the FAIR guiding principles. FAIR aims to make data findable, accessible, interoperable, and reusable (Wilkinson et al. 2016).\nAlso, check out GO FAIR, “a bottom-up, stakeholder-driven and self-governed initiative that aims to implement the FAIR data principles.” I borrow examples from this site. \n\n\n\n\n\n\nDocument, Discover, and Interoperate\n\n\n\nDocument, Discover, and Interoperate (DDI) is a standard that follows the FAIR principles and many major data repositories like ICPSR uses DDI!\n\n\n\n\n\n\n\n\nFigure 5.5: Charlie Conspiracy meme from the TV Show, “Always Sunny in Philidelphia,” that says, “Searching for the right data without a catalog.”\n\n\n\n\n5.4.1 Findable\n1. Data and metadata are assigned a globally unique, eternally persistent identifier.\nTwo common examples are ORCID (Open Researcher and Contributor ID) and DOI (Digital Object Identifier). Both are used in a paper I recently published here.\n2. Data are described with rich metadata.\nMore details the better! Imagine what information you would like to know. Some potential information could be descriptive about the context, quality and condition, how the data were collected and cleaned, or characteristics of the data.\n3. Metadata clearly and explicitly include the identifier of the data they describe.\n\nThe metadata and the dataset they describe are usually separate files. The association between a metadata file and the dataset should be made explicit by mentioning a dataset’s globally unique and persistent identifier in the metadata\n\n4. (Meta)data are registered or indexed in a searchable resource.\nEven if the data have identifies and rich metadata, that doesn’t guarantee that the data is findable. This is why data curators will often use well-known data repositories to house their data, such as ICPSR and Harvard Dataverse (Urban has one too called the Urban Data Catalog!).\n\n\n5.4.2 Accessible\n1. (Meta)data are retrievable by their identifier using a standardized communication protocol.\n\nThe protocol is open, free, and universally implementable.\nThe protocol allows for an authentication and authorization procedure, where necessary.\n\nHypertext Transfer Protocol Secure (HTTPS), File Transfer Protocol Secure (FTPS), and Phone numbers (arguably not universally-implementable, but close enough) are all examples of such identifiers.\n2. Metadata are accessible, even when data are no longer available.\n\nDatasets tend to degrade or disappear over time because there is a cost to maintaining an online presence for data resources. When this happens, links become invalid and users waste time hunting for data that might no longer be there. Storing the metadata generally is much easier and cheaper. Hence, principle Accessible 2 states that metadata should persist even when the data are no longer sustained. Accessible 2 is related to the registration and indexing issues described in F4.\n\n\n\n5.4.3 Interoperable\n1. (Meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation.\nData should be readable and interpretable by both humans and computers without needing specialized tools. The goal is a common understanding of digital objects using a standard knowledge representation language. This language should have a precise formal specification, be accessible for learning, and support interoperability across multiple scenarios.\n2. (Meta)data use vocabularies that follow the FAIR principles.\nWhen describing data or metadata, we use vocabularies that must be FAIR so they can be found, accessed, interoperated, and reused by humans and machines. These vocabularies should have globally unique and persistent identifiers, be well-documented, and easily accessible. Communities should set FAIRness standards, ensuring vocabularies meet criteria such as unique identifiers (Findable 1), resolvable via standard protocols (Accessible 1), and described in a formal, accessible language (Identifiable 1).\n3. (Meta)data include qualified references to other (meta)data.\nA qualified reference is a cross-reference that specifies its intent, such as “X is regulator of Y” rather than just “X is associated with Y.” The goal is to create meaningful links between (meta)data resources to enrich contextual knowledge, while balancing the effort required to develop a good data model. Specify relationships such as one dataset building on another or needing complementary data, and describe scientific links between datasets. Additionally, all datasets should be properly cited with globally unique and persistent identifiers.\n\n\n5.4.4 Reusable\n1. (Meta)data are richly described with a plurality of accurate and relevant attributes\nOthers can more easily reuse the data if there are many labels/information attached to the data. Some examples are what was the purpose of the data collection, what are the limitations, what were the conditions for the data collection, has the data been cleaned, are the variables explained or self-explanatory, etc.\n\n(Meta)data are released with a clear and accessible data usage license.\n\nHere is a page to help choose a license.\n\n(Meta)data are associated with detailed provenance.\n\n\nFor others to reuse your data, they should know where the data came from (i.e., clear story of origin/history, see Readability 1), who to cite and/or how you wish to be acknowledged. Include a description of the workflow that led to your data: Who generated or collected it? How has it been processed? Has it been published before? Does it contain data from someone else that you may have transformed or completed? Ideally, this workflow is described in a machine-readable format.\n\n\n(Meta)data meet domain-relevant community standards.\n\nData reuse is easier when datasets are similar: same type, standardized organization, sustainable formats, and common documentation templates. FAIR data should meet these standards to enhance usability. If deviations from standard practices are necessary, reasons should be specified in the metadata. Note that FAIR principles do not address data quality, which depends on the intended application.\n\n\n5.4.5 Searching for metadata\n\n\n\n\n\n\nClass Activity 4\n\n\n\nYou will be given 20 minutes to complete this in-class activity.\nEach of you have been assigned a topic based on your last homework assignment (Week 2) or randomize (see table below).\n\nFind a digital object to answer questions: Based on your assigned topic, find an article, dataset, image, or any digital object that matches or is highly related to that topic from a digital repository that has enough metadata to answer the at least half of the following questions:\n\n\nWhat is the title of the digital object?\nWho is the author/creator?\nWhen was the digital object published?\nWhat keywords are associated with the digital object?\nWhat is the abstract or description of the digital object?\nWhat file formats are available?\n\nBelow are a few repositories you could start your search with, but feel free to use whatever search tools at your disposal (e.g., use your Google-Fu) to find a digital object with reasonable amount of metadata information.\n\nData.Gov\nFiveThirtyEight\nfigshare\nFinancial Times\nHarvard Dataverse\nICPSR\nIMDb Non-Commercial Datasets\nMendeley Data\nNatural History Museum Data Portal\nZenodo\n\n\nAssess the metadata quality: Based on the answers to these questions, how would you assess the data quality? In other words,\n\n\nIs the metadata sufficient to understand the digital object’s content and purpose?\nAre there any missing or unclear metadata elements based on the FAIR principles?\nHow could the metadata be improved to enhance the digital object’s usability?\n\n\n\nTopic assignments:\n\n\n\nStudent Last Name\nTopic\n\n\n\n\nBlack\nInternational politics\n\n\nBoes\nFinancial trade\n\n\nCohen\nHigh fantasy\n\n\nColeman\nDomestic justice system\n\n\nDeAngelo\nMedical images\n\n\nDuff\nSocial media images\n\n\nFlynn\nClassical music\n\n\nGomez\nHistorical events\n\n\nKeohane\nDigital advertising\n\n\nKiely\nGambling\n\n\nLarsson\nForgeries\n\n\nLombardi\nTracking devices\n\n\nMacro\nAutomobiles\n\n\nMathews\nHealthcare facilities\n\n\nMeslin\nInternet searches\n\n\nNorton\nJournalism\n\n\nNovakoski\nPhone calls\n\n\nRussell\nDomestic politics\n\n\nSchreifels\nGenetics\n\n\nScully\nMental health\n\n\nSokolova\nClothing retail\n\n\nWeir\nInternational education\n\n\nWilliams\nDomestic education\n\n\n\n\n\n\n\nChoi, Jung Hyun, Alanna McCargo, Michael Neal, Laurie Goodman, and Caitlin Young. 2019. “Explaining the Black-White Homeownership Gap.” Urban Institute. https://www.urban.org/research/publication/explaining-black-white-homeownership-gap-closer-look-disparities-across-local-markets.\n\n\nDenning, Dorothy Elizabeth Robling. 1982. Cryptography and Data Security. Vol. 112. Addison-Wesley Reading.\n\n\nFellegi, Ivan P. 1972. “On the Question of Statistical Confidentiality.” Journal of the American Statistical Association 67 (337): 7–18.\n\n\nFienberg, Stephen E, and Jiashun Jin. 2018. “Statistical Disclosure Limitation for~ Data~ Access.” In Encyclopedia of Database Systems (2nd Ed.).\n\n\nICPSR. n.d. “Guide to Social Science Data Preparation and Archiving: Best Practice Throughout the Data Life Cycle: 6th Edition.” https://www.icpsr.umich.edu/web/pages/deposit/guide/.\n\n\nKitchin, Rob. 2014. The Data Revolution: Big Data, Open Data, Data Infrastructures and Their Consequences. Sage.\n\n\nStern, Alena, and Ajjit Narayanan. 2021. “Ethics and Empathy in Using Imputation to Disaggregate Data for Racial Equity.” https://www.urban.org/research/publication/ethics-and-empathy-using-imputation-disaggregate-data-racial-equity-case-study-imputing-credit-bureau-data.\n\n\nTraub, Amy, and Sean McElwee. 2016. “Bad Credit Shouldn’t Block Employment: How to Make State Bans on Employment Credit Checks More Effective.” Washington, DC: Demos.\n\n\nWilkinson, Mark D, Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al. 2016. “The FAIR Guiding Principles for Scientific Data Management and Stewardship.” Scientific Data 3 (1): 1–9.",
    "crumbs": [
      "Data Storage and Sharing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Storage</span>"
    ]
  },
  {
    "objectID": "03_data-storage.html#footnotes",
    "href": "03_data-storage.html#footnotes",
    "title": "5  Data Storage",
    "section": "",
    "text": "“Cognitive tests, pilot tests, focus groups, and other tools can be used to understand how respondents interpret your questions and instructions, understand the meaning of survey questions, and to write better questions. This type of testing can also evaluate different survey techniques used in the field to increase response or cooperation, and can help you sort out the meaning of survey responses.” Overview of Cognitive Testing and Questionnaire Evaluation.↩︎\n“Pretty Good Privacy is an encryption program that provides cryptographic privacy and authentication for data communication.” from https://en.wikipedia.org/wiki/Pretty_Good_Privacy↩︎",
    "crumbs": [
      "Data Storage and Sharing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Data Storage</span>"
    ]
  },
  {
    "objectID": "03_job-market-time-management.html",
    "href": "03_job-market-time-management.html",
    "title": "6  Job Market and Time Management",
    "section": "",
    "text": "6.1 On the job market",
    "crumbs": [
      "Data Storage and Sharing",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Job Market and Time Management</span>"
    ]
  },
  {
    "objectID": "03_job-market-time-management.html#on-the-job-market",
    "href": "03_job-market-time-management.html#on-the-job-market",
    "title": "6  Job Market and Time Management",
    "section": "",
    "text": "Figure 6.1: Futurama Fry meme with the text, “Not sure if I’m highlighting my strengths and character traits for I’m bragging profusely.”\n\n\n\n\n6.1.1 How do you explore new job opportunities…\nwhile being respectful of your current employer and avoiding the “grass is greener” syndrome?\nWe will break down the answer to this question in four parts.\n\nKeep your materials up-to-date: Start by updating your resume, LinkedIn profile, and other professional materials. Personally, I update my CV/resume about every month, typically during the first week. In my field, it’s common to have an updated CV for grant and contract applications. If you regularly maintain your resume or professional social media presence, it won’t raise suspicions with your employer.\nThink about why you are seeking another opportunity: Reflect on the key reasons for wanting to leave your current position. Is it a temporary annoyance, or is it a systemic issue that, if unresolved, will continue to affect your happiness?\nFor example, one of the most common reasons for leaving a job is having a difficult supervisor. Even if you enjoy your work, colleagues, and company, a bad supervisor can be a compelling reason to leave. Supervisors play a crucial role in advocating for key changes on your behalf, finding professional opportunities, and advancing your career. They are often responsible for your raises and promotions. Without a supportive supervisor, your career may stagnate or become difficult to advance.\nSchedule interviews outside of work hours: When scheduling interviews, try to arrange them outside of your work hours. It is unethical to use work time for interviews. Some people take time off, make up the hours later in the day, or schedule interviews outside of their regular work hours.\nWrap up your projects neatly: As a supervisor who oversees several people, my biggest request before someone leaves is that they wrap up their projects and responsibilities neatly. This means leaving clear instructions, passing on knowledge, and identifying someone who can serve as a backup until a new person is hired. Additionally, take on quick tasks that can be completed before your departure to help your colleagues with bigger projects.\nFor example, one of my team members who helped managed my largest projects was leaving for graduate school. I had already identified a new person to take over her responsibilities. I asked the departing employee to train the new person, clean up the project directory, create read-me files or instructions for each subdirectory/responsibility, and meet with the new person to walk through those materials and responsibilities.\n\n\n\n\n\n\n\nUnpopular opinion: Proceed with caution!\n\n\n\nI once received advice to apply for a job occasionally (e.g., once a year) even if you are happy with your current position. Applying for new positions informs you about how competitive your skills are in the job market (i.e., what you are worth). You may learn something new about yourself or what you value. You may also discover an even better opportunity than you currently have.\n\n\n\n\n6.1.2 What are the key elements of a good cover letter?\n\n\n\n\n\n\nFigure 6.2: First World Problems meme that says, “They want a cover letter. Now I can’t apply for the job.”\n\n\n\nIt goes without saying that most people (myself included) do not like writing cover letters. However, a good cover letter is important and should be customized to the job, highlighting how your experiences align with the job description. A cover letter typically has the following structure:\n\nFormal greeting: The greeting is usually to the hiring manager to the hiring committee (if known). If unknown, you can use something generic like “Dear Hiring Manager.”\n\n\nDear [Hiring Manager’s Name or Group],\n\n\nIntroduction: The first paragraph or few sentences should state the position you are applying for, mention how you found out about the job opening (this is nice to know as the hiring manager), and provide a brief statement about why you are interested in the position or the company.\n\n\nI am excited to apply for the position of [Position Name] at [Company Name] that was posted on [Where You Found the Job Posting]. With my background in [Your Field or Industry] and experience in [Relevant Experience], I am excited about the opportunity to contribute to your team.\n\n\nOr you could have the following for the last sentence.\n\n\nPlease accept this letter and my resume as my application for the position.\n\n\nBody Paragraphs: The next two or three paragraphs should highlight your most recent and relevant experiences and how they match the job posting. Be specific! Simply stating that you are “organized” or “a good communicator” does not demonstrate this to the hiring manager. Provide specific examples from your experience to illustrate these qualities.\n\n\nI feel that my qualifications are well matched to the posted job description and requirements. I am seeking an opportunity to challenge and build upon my knowledge and experiences. At present, I am [Role, Responsibilities, Skills, etc.]. This experience has equipped me with the skills necessary to [Relevant Experience].\n\n\nUsually in second to last paragraph, you want to say why you are good fit for the company and why you are interested in that company.\n\n\nMy experiences, skills, and drive have prepared me to be an invaluable contributor to the [Company]. Moreover, being a part of [Company] would be ideal for my career as it would [Your Professional Goal and Alignment with Company Values/Mission].\n\n\nClosing paragraph: This paragraph should reiterate your interest in the position, mention how to find more information (if not already stated at the beginning), explain how they can contact you for next steps, and thank the hiring manager for considering your application.\n\n\nI am eager in taking the next step in this process, please feel free to contact me by phone or email. I appreciate you taking the time to review my application, and I look forward to hearing from you soon.\n\n\nAnother example.\n\n\nI am excited to bring my skills and experience to [Company]. I have attached my resume for your review and would love the opportunity to discuss further how my background, skills, and certifications will contribute to your team. Thank you for considering my application.\n\n\n\n\n\n\n\nHeavily edit AI cover letters!\n\n\n\nIf you’re going to use AI like ChatGPT to write your cover letter, make sure to heavily edit it afterward. AI is a tool, not a crutch. I’m currently reviewing job applications, and I can easily tell which ones were created with AI. The bonus for me is knowing which applicants to ignore.\nThis isn’t to say you shouldn’t use AI. HR and other companies are obviously using AI to filter applicants, so why not use the tool to help you? However, as I said, don’t just generate the cover letter without editing it to add your own voice. One of the applicants my colleague and I invited for a phone screen stood out mostly due to her cover letter being so unique and thoughtful.\n\n\n\n\n6.1.3 What are some tips for interviewing well?\n\n\n\n\n\n\nFigure 6.3: Dwight Schrute meme that says, “Am I ready for this interview? False. Is this interview ready for me?”\n\n\n\nHere are some general tips:\n\nResearch your interviewers (if you know who they are). They will likely look you up, so it’s only fair you do the same. One candidate impressed me by reading a couple of my papers and sharing his thoughts during the interview.\nPrepare an introduction about yourself that is concise, with a longer version ready if asked to elaborate.\nResearch the company and be ready to explain why you’re applying for the role and why you want to work for the company.\nDress appropriately and arrive on time if the interview is in person. For virtual interviews, ensure good sound quality, a suitable background, proper lighting, and a functioning camera. First impressions matter, even on video calls.\n\n\n\n\n\n\n\nFigure 6.4: Two people shaking hands from the TV Show, “The Office.”\n\n\n\n\n\n\n\n\n\nPractice your handshake\n\n\n\nIf you feel your handshake isn’t strong, consider practicing it with family, friends, or anyone willing to provide honest feedback. I understand it can be challenging for men, as they may worry about exerting too much pressure on women’s hands. However, women have the advantage in this regard, as we are less likely to apply excessive force. So, don’t hesitate to give a firm handshake!\n\n\n\nTake your time if needed. It’s okay to say, “Can I have a moment to think about this question?” before answering. It’s better to gather your thoughts than to give a rushed or repetitive answer. Interviewers appreciate clear and concise responses.\nSpeak clearly and confidently. If the interview is on video or in person, try to smile and show enthusiasm, even if you’re nervous. Some roles require strong public speaking skills.\nPrepare your own questions for the interviewer. Remember, you’re also interviewing them!\nFollow up with a thank-you note reiterating your interest in the position.\n\n\n\n\n\n\n\nTake notes on how your interviewers responded to your questions\n\n\n\nWhen I was on the job market after graduate school, I had a set of questions I loved asking interviewers. I would note their responses so that I could mention them in my follow-up thank-you email. I found that many of them would respond and comment on my email.\n\n\n\n\n6.1.4 How to negotiate salaries?\nBefore delving into salary negotiations, it’s essential to research the typical salary range for the specific role and responsibilities, taking into account the geographical location. Professional societies such as the American Statistical Association conduct surveys among their members, gathering valuable salary data. Additionally, consider reaching out to friends and family occupying similar positions, if they’re willing to share their salary information. While discussing salaries is often considered taboo, breaking this silence can be empowering for employees, rather than solely benefiting employers.\nMany employers are obligated to disclose salary ranges, although some ranges may not be ideal (e.g., very wide). As a hiring manager, understanding your salary expectations is crucial, as it enables me to gauge whether my company can offer a suitable salary within that range (bearing in mind that I have limited control over the predetermined salary bands). This ensures that neither your time nor mine is wasted, minimizing frustration for both parties involved.\nWhen presented with a salary offer, whether verbally or written, it’s advisable not to immediately accept or reject it. If the offer is verbal, take a moment before responding, expressing gratitude for the offer without revealing your opinion on its adequacy. You should mull over the offer for at least a day, carefully considering the other benefits such as vacation time and healthcare provisions in addition to the compensation.",
    "crumbs": [
      "Data Storage and Sharing",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Job Market and Time Management</span>"
    ]
  },
  {
    "objectID": "03_job-market-time-management.html#time-management",
    "href": "03_job-market-time-management.html#time-management",
    "title": "6  Job Market and Time Management",
    "section": "6.2 Time management",
    "text": "6.2 Time management\n\n\n\n\n\n\nFigure 6.5: Gru Plan meme. First panel says, “Make a list of things to do tomorrow.” Second panel says, “Set an alarm to hold myself accountable.” Third panel says, “Ignore the alarm and spend all day tagging friends in memes.” Fourth panel says, “Ignore the alarm and spend all day tagging friends in memes.”\n\n\n\n\n6.2.1 What are effective ways to stay organized?\nUnderstanding what drives you or what triggers your need for organization is key. For instance, I thrive on maintaining an “inbox zero” approach. To align with this, I create subfolders within my inbox to categorize emails related to projects, administrative tasks, and more. Each email must be addressed and filed in the appropriate folder before I can clear it from my main inbox.\n\n\n\n\n\n\nFigure 6.6: The first level of my inbox organization\n\n\n\nAnother strategy I employ is keeping essential information visible. I use my whiteboard to track my professional travel schedule, paper reviews, and the progress of paper publications. This whiteboard also helps me see if I’ve been overcommitting on these areas.\nFor day-to-day tasks, I rely on a notebook. At the start of each day, I list the top 2 to 4 priorities I aim to accomplish. Alongside, I maintain a to-do list, tackling tasks based on their importance and urgency. Breaking down larger projects into smaller, manageable steps also helps maintain clarity and progress.\n\n\n6.2.2 How can you avoid forgetting deadlines?\nTo ensure I never miss deadlines, I maintain a secondary calendar dedicated solely to reminders. This calendar prompts me to complete tasks and also reminds others of their responsibilities. I strongly recommend implementing a similar system. Examples of reminders I set include “set agenda for W meeting,” “create announcement for X,” “send email reminder for Y,” and “send follow-up if Z doesn’t respond.”",
    "crumbs": [
      "Data Storage and Sharing",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Job Market and Time Management</span>"
    ]
  },
  {
    "objectID": "03_data-sharing-transfer.html",
    "href": "03_data-sharing-transfer.html",
    "title": "7  Data Sharing and Transfer",
    "section": "",
    "text": "7.1 Importance of sharing data\nFienberg (1994) outlines the ethical, institutional, legal, and professional dimensions for sharing statistical data in biomedical and health sciences, but these ideas apply to all data. I also continue to draw from the guide by ICPSR (n.d.).",
    "crumbs": [
      "Data Storage and Sharing",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Sharing and Transfer</span>"
    ]
  },
  {
    "objectID": "03_data-sharing-transfer.html#importance-of-sharing-data",
    "href": "03_data-sharing-transfer.html#importance-of-sharing-data",
    "title": "7  Data Sharing and Transfer",
    "section": "",
    "text": "Class Activity 1\n\n\n\nFrom this short video, what data sharing issues can you identify?\n\n\n\n\n7.1.1 Required by law or funding support\nOne of the foremost reasons for sharing data is that it is often mandated by law or funding sources, such as the National Science Foundation and the National Institutes of Health, two of the largest funders of scientific research in the US. Unfortunately, some researchers are not diligent about following through or find loopholes, such as claiming the information is too sensitive to share or has proprietary aspects.\n\n\n7.1.2 Scientific rigor\nMaking data publicly available has several key benefits for the scientific community. It reinforces open scientific inquiry, as the self-correcting features of science work most effectively when data are widely available. It encourages diversity of analysis and opinions, enabling researchers to challenge each other’s analyses and conclusions. It promotes new research and allows for testing new or alternative methods, with numerous examples of data being used in ways the original investigators had not envisioned. Additionally, it improves methods of data collection and measurement through the scrutiny of others. Overall, making data publicly available helps the scientific community reach consensus on various methods.\n\n\n7.1.3 Cost reduction\nReduces costs by avoiding duplicate data collection efforts. From ICPSR (n.d.):\n\nSome standard datasets, such as the General Social Survey and the National Election Studies, have produced literally thousands of papers that could not have been possible if the authors had to collect their own data. Archiving makes known to the field what data have been collected so that additional resources are not spent to gather essentially the same information.\n\n\n\n7.1.4 Training\nData are also an important resource for training the next generation of researchers and for working professionals seeking to improve their technical skills. For instance, think back to your past courses when you were learning a new technical skill. Did it help to have a realistic dataset to test your skills on?\nAn example the Urban Institute collaborated with the Allegheny County Department of Human Services and the Western Pennsylvania Regional Data Center (WPRDC) to create a synthetic version of the County’s confidential social and human service utilization data. Synthetic data replace actual records in a dataset with pseudo-records, with the goal of closely mimicking key distributional and statistical properties of the original records. This allows agencies to release data disaggregated by race and ethnicity while reducing the risk of privacy violations. Graduate students at the University of Pittsburgh examined the data and confirmed that it could be used effectively, for instance, to allocate resources for overdose prevention.\n\n\n7.1.5 Data of the people, by the people, and for the people\nFinally, I like to say that these data are often “of the people, by the people, and for the people.”\nThe data are of the people, in the sense that people do care about their privacy and their confidential data. Although they may be willing to trade off information a bit at a time to private sector actors for useful purposes, many people would be deeply unhappy if their personal data was widely available.\nThe data are also by the people, in the sense that government collection of people’s information is supported by taxpayer dollars. Therefore, one could argue that anonymized individual-level data should be accessible to data users—such as data practitioners, external researchers, or public policymakers.\nLiterally volumes of research could be cited here about how increased access to government data results in social good for the people.\n\n\n\n\n\n\nOpen-source code is also important!\n\n\n\nThe reasons for sharing data applies to sharing code.",
    "crumbs": [
      "Data Storage and Sharing",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Sharing and Transfer</span>"
    ]
  },
  {
    "objectID": "03_data-sharing-transfer.html#secure-data-access",
    "href": "03_data-sharing-transfer.html#secure-data-access",
    "title": "7  Data Sharing and Transfer",
    "section": "7.2 Secure data access",
    "text": "7.2 Secure data access\nOver the years, government agencies have been moving slowly toward allowing more data users direct access to the underlying cleaned data, under strict controls.\n\n7.2.1 Secure enclaves\nAn example of direct data access is through a secure enclave, such as the Federal Statistical Research Data Centers.1 This secure enclave became available in 1982 (then called the Center for Economic Studies), after data users demanded access to better quality data when the US Census Bureau became more aggressive with its applications of statistical data privacy methods on its data products.\nAlthough more secure facilities are becoming available (for example, the National Science Foundation Secure Data Access Facility2), researchers face several challenges to obtain this direct access. Full access to these data is only available to select government agencies, a limited number of data users working in collaboration with analysts from those agencies, or through highly selective research programs administered by these agencies. Further, data users are often required to be US citizens, undergo lengthy clearance processes to gain direct access (which can take months or years), and submit extensive research proposals.\n\n\n\n\n\n\nFederal Statistical Research Data Centers\n\n\n\nAt the time of publication, the textbook mentions there are 30 Federal Statistical Research Data Centers (Bowen 2021). At the time of this course, there are 33. See the U.S. Census Bureau’s webpage on Federal Statistical Research Data Centers for the number and locations.\nThe 33 Federal Statistical Research Data Centers across the United States may seem like enough to be geographically accessible to most data users. But that is not the case. These data centers are primarily located in places with large academic institutions. For me, living in Santa Fe, New Mexico (the state capital), the closest is a 7.5-hour drive to Boulder, Colorado. Moreover, remote access to these data centers grants access to only a limited selection of confidential data and requires a setup that simulates a secure enclave working station, which may prove challenging for many individuals.\n\n\n\n\n7.2.2 Restricted access\nSometimes confidential data will need to be transferred to an external systems for further analysis. The following are two safe options that are standard ensure a secure file transfer:\n\nFile transfer using secure electronic connections. Most workplaces have Secure File Transfer Protocol (SFTP) servers to allow external parties to exchange data with them through encrypted connections. This also includes encrypted emails, file transfers to file hosting services (e.g., Dropbox), survey tools (e.g., Qualtrics), and other services using browser-based transfers with Transfer Layer Security (TLS).\nFile transfers using compressed (e.g., zipped), encrypted, password protected files to emails where the password is shared by another means by phone or text message and the encryption is FIPS 140-2 complaint, usually AES 128 or AES 256.\n\n\n\n\n\n\n\nDO NOT EMAIL DATA WITHOUT ENCRYPTION!\n\n\n\nDo not share data through unencrypted file transfers over the Internet or in the body of, or as an unencrypted attachment to, an unencrypted email. Always consider some form of SFTP!\n\n\nYou can also restrict access by limiting the use of confidential variables. For example, if a file is considered confidential because it contains identifying names and addresses, those variables may be removed from the file and replaced with pseudo identifiers. The sanitized file can then be used and shared without risk of violating confidentiality. You can also regulate access restrictions by limiting people within your workplace from accessing specific computer accounts or files.\n\n\n\n\n\n\nClass Activity 2\n\n\n\nWe’ve learned about secure data access. What are the privacy, security, ethics, and equity implications of this type of data access?",
    "crumbs": [
      "Data Storage and Sharing",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Sharing and Transfer</span>"
    ]
  },
  {
    "objectID": "03_data-sharing-transfer.html#public-data-files-and-statistics",
    "href": "03_data-sharing-transfer.html#public-data-files-and-statistics",
    "title": "7  Data Sharing and Transfer",
    "section": "7.3 Public data files and statistics",
    "text": "7.3 Public data files and statistics\nThe following is discussed in Bowen (2021) and Bowen (2024).\nFor decades, government agencies produced public use data and statistics. During the pre-computer era in the early to mid-1900s, public use data were available to those who braved the “government documents” section of research libraries or those who physically went to government offices to inspect available files. But government agencies typically reported summary statistics, such as total spending on unemployment insurance and total number of people receiving it. Knowing such information on a county-by-county or metro-area basis did not pose much threat to privacy.\nAs the computer era arrived, government agencies started to provide more detailed public use data that could be directly accessible to both researchers and the general public. For example, the Statistics of Income Division of the Internal Revenue Service releases a public use file for data users based on administrative taxpayer data. Several organizations, such as the American Enterprise Institute (DeBacker, Evans, and Phillips 2019), the Urban-Brookings Tax Policy Center (McClelland et al. 2019), and the National Bureau of Economic Research (Bierbrauer, Boyer, and Peichl 2021), develop microsimulation models based on this public use file that inform the public on potential impacts of tax policy proposals.\nTo ensure that these public use data protect individual privacy, extensive statistical data privacy methods (or statistical disclosure control) are implemented. Here, I will use a fictitious socioeconomic dataset to illustrate a range of such methods. For a more comprehensive overview of these methods, Matthews and Harel (2011) offer a detailed review, while McKenna and Haubach (2019) summarize the specific statistical data privacy methods employed by the US Census Bureau.\n\n\n\n\n\n\nStatistical Disclosure Control\n\n\n\nStatistical Disclosure Control (SDC), sometimes referred to as Statistical Disclosure Limitation (SDL), is a field of study. It aims to develop and apply statistical methods that enable the release of high-quality data products while reducing the risk of disclosure, or release of sensitive information contained in the data.\n\n\nThese methods have existed within statistics and the social sciences since the mid-20th century; researchers have likely encountered some of them before, even outside of the privacy context. SDC can be as simple as:\n\nsuppressing (not releasing or withholding) certain records or results,\naggregating variables into larger groups (like reporting state-level data rather than county-level data), or\nrounding numeric values to make them less distinct.\n\n\n7.3.1 Statistical Disclosure Control Methods\nChapter 3 of Bowen (2021) walks through these methods using a famous piece of art. For our class, we will review these methods again, but with a fictitious micro-level socioeconomic dataset.\nSuppose this fictitious micro-level socioeconomic dataset contains hundreds of records for individuals residing in Santa Fe, NM.\n\n\n\n\n\n\nFigure 7.1: Fictitious Santa Fe, NM, Socioeconomic Data\n\n\n\nFigure 7.1 displays a sample of eight records from the dataset, which includes the person’s name, age, education, and income.\n\n\n7.3.2 Suppression\n\n\n\n\n\n\nFigure 7.2: Removing personally identifiable information\n\n\n\nAs a first step, most personally identifiable information, such as names, should be removed from the data (see Figure 7.2). An obvious step is to replace names with numbers. Data curators, who are responsible for safeguarding the data, may generate individual level identification numbers if they plan to link the data with other information. If there is no intention to link the data with another source, the variable may be entirely removed.\nAfter removing the personally identifiable information, the most common statistical data privacy method is suppression, which involves the removal of certain values from the data. This approach is easy and quick to implement. As an example, when I attended high school in a remote area of Idaho, I was the only Asian American student. Even with names removed, a data intruder could identify me in a dataset that included information on race/ethnicity. To ensure my privacy, such information could be removed or suppressed.\n\n\n7.3.3 Rounding\n\n\n\n\n\n\nFigure 7.3: Rounding income\n\n\n\nAnother privacy concern in the fictitious dataset is the reporting of income values to the nearest dollar. To make the records less identifiable, we can round the income values. Instead of rounding to the nearest hundred or thousand, some rounding methods introduce randomization in rounding up or rounding down significant figures.\nFor instance, consider an individual with an income of $596. If we want to round the value to the closest $10, then there is a 60 percent probability of rounding the income up to $600 and a 40 percent probability of rounding it down to $590.\nThere are also other rounding schemes, such as the one utilized by the U.S. Census Bureau, which we implement for the fictitious dataset (see Figure 7.3). In this approach,\n\n$0 is rounded to $0,\n$1–7 rounded to $4,\n$8–$999 rounded to nearest $10,\n$1,000–$49,999 rounded to nearest $100, and\n$50,000+ rounded to nearest $1,000.\n\n\n\n7.3.4 Generalization\n\n\n\n\n\n\nFigure 7.4: Generaliziation\n\n\n\nAnother statistical data privacy method is known as generalization, aggregation, or categorical thresholding. When applying this method, the detailed information is consolidated into broader categories. In our example, we can generalize the education groups, which would decrease or eliminate the number of distinct observations. Figure 7.4 demonstrates how we changed the education levels of “high school,” “some college,” “bachelor’s,” “master’s,” and “doctorate” into broader categories such as “no college,” “bachelor’s,” and “graduate degree.”\n\n\n7.3.5 Noise infusion\n\n\n\n\n\n\nFigure 7.5: Infusing noise\n\n\n\nAdding or subtracting random values is another popular statistical data privacy method. One way to generate random values is within specific boundaries (for example, –10 to 10) or based on a probability distribution (for example, a bell curve centered at zero). This method is known as adding noise, injecting noise, sanitizing results, or perturbing the data. In Figure 7.5, noise has been added to the age variable, resulting in new age values. The random noise is drawn from a bell curve–shaped distribution, such as a normal or Gaussian distribution. We see that some of the added or subtracted values are very small (like 0, 1, and 2), while a few are larger values (for example, 6 and 7). Introducing random values creates some uncertainty, making it more challenging for a malicious actor to discern the original age value.\n\n\n7.3.6 Top- and Bottom-coding\nTop coding/bottom coding limits values above/below a threshold to the threshold value (i.e., individuals over age 95 are recoded to age 95 or a “95 and over” category). For our data, we could top- and bottom-code our Age category to substitute “greater than 85” and “less than 18” rather than the exact values.\n\n\n7.3.7 Sampling\nA common statistical disclosure control approach for protecting microdata files that are released to the public, in addition to such methods as top-coding, is to select a subsample of respondents. The Census Bureau pioneered public-use microdata sample files when it released a 1-in-1000 sample of respondents from the 1960 census.\nStatistical agencies use subsampling to introduce some form of “plausible deniability” to protect data in public-use microdata files produced from censuses and sample surveys. The general idea is that if someone tried to identify a record in one released dataset with another publicly available dataset, they cannot guarantee the match is correct because the released data are a random subset of the original.\n\n\n7.3.8 Synthetic data\nIn recent decades, synthetic data has become one of the most popular statistical disclosure control methods among privacy researchers. Synthetic data consist of pseudo or “fake” records that are statistically representative of the original, confidential data. Imagine we collect information on where people traveled for a conference in Boston, MA. The confidential data show that 50 out of the 100 participants are already from Boston, MA. One way to generate synthetic data for this sample is to flip a coin 100 times and report the number of heads results as the number of people from Boston, MA.\nStatisticians originally developed synthetic data to address missing data in clinical trial scenarios. Patients often drop out of such studies because they last for several months or years. The statisticians created new observations or values for the missing data by developing a model based on the remaining patient data. The idea of synthetic data is attractive to federal agencies because they contain only “fake” records. But most federal agencies don’t use synthetic data yet. This is mostly because of limited human resources (i.e., lack of practitioners who are knowledgeable of the methods and can implement them) and computational resources (i.e., code and proper computing equipment).\nIn general, synthetic data can be created either based on a model or not based on a model (i.e., with parametric or nonparametric methods). At a high level, the non-model-based approaches calculate the estimates or percentages of counts from the data and use those estimates as weights for a weighted random sampling scheme. Our earlier Boston, MA, conference example would be considered a non-model-based approach, where the weight for the randomization scheme is 50 percent.\nModel-based methods rely on estimating or learning an appropriate model based on the confidential data; “fake” records are then created from the model. As an example, suppose we collect the heights of our conference attendees. When we plot the data, we see that the distribution of attendees’ heights is similar to a bell curve or normal distribution and decide to use that model to generate our synthetic data.\nThe use of synthetic data relies heavily on selecting an appropriate model to preserve the data’s statistical features, and this reliance has a few potential drawbacks. One is that the privacy expert must be careful when selecting and using a model that perfectly replicates the confidential data. Some privacy researchers advise splitting the data into multiple parts so that one part can help inform and develop the model while other parts help verify the model’s quality. Another concern is that if the privacy expert selects a poor model, the synthetic data will provide improper results for data users. This also means that developing a model to capture every interesting feature in more complex data without recreating the confidential data is extremely difficult.\nFor more technical details on synthetic data, check out Hu and Bowen (2024).\n\n\n\n\n\n\nClass Activity 3\n\n\n\nSuppose you are tasked with releasing a public version of a K-12 education dataset. This dataset contains information about all students in a state, specifically their names, ages, genders, home addresses, and standardized test scores.\n\nWhat SDC methods would you apply to protect this data?\nWhat checks would you make to ensure the dataset is sufficiently protected?\nHow would you ensure the dataset is sufficiently useful?\nWhat are the possible ethical and equity considerations when implementing the selected SDC methods?",
    "crumbs": [
      "Data Storage and Sharing",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Sharing and Transfer</span>"
    ]
  },
  {
    "objectID": "03_data-sharing-transfer.html#week-4-assignment",
    "href": "03_data-sharing-transfer.html#week-4-assignment",
    "title": "7  Data Sharing and Transfer",
    "section": "7.4 Week 4 Assignment",
    "text": "7.4 Week 4 Assignment\n\n\n\n\n\n\nDEADLINE\n\n\n\nDue June 13, at 11:59 PM EDT on Canvas\n\n\n\n7.4.1 Read\n\nChapter 4: How Do Data Privacy Methods Avoid Invalidating Results?\nChapter 5: What Makes Datasets Difficult for Data Privacy?\n\n\n\n7.4.2 Write (600 to 1200 words)\nFind a news analysis story3 published within the last year (2023 – present) and answer the following questions:\n\nWhat does the article claim?\nDoes the content of the article apply to you, your family, and/or your community?\nWhat makes you believe the conclusions?\nWho wrote the article?\nWhere did the article get their facts?\nWhat “red flags” (if any) do you notice?\nWould the story change if there was more or less access to data? What would be that story?\n\n\n\n\n\nBierbrauer, Felix J, Pierre C Boyer, and Andreas Peichl. 2021. “Politically Feasible Reforms of Nonlinear Tax Systems.” American Economic Review 111 (1): 153–91.\n\n\nBowen, Claire McKay. 2021. Protecting Your Privacy in a Data-Driven World. Chapman; Hall/CRC.\n\n\n———. 2024. “Government Data of the People, by the People, for the People: Navigating Citizen Privacy Concerns.” Journal of Economic Perspectives 38 (2): 181–200.\n\n\nDeBacker, Jason, Richard W Evans, and Kerk L Phillips. 2019. “Integrating Microsimulation Models of Tax Policy into a Dge Macroeconomic Model.” Public Finance Review 47 (2): 207–75.\n\n\nFienberg, Stephen E. 1994. “Sharing Statistical Data in the Biomedical and Health Sciences: Ethical, Institutional, Legal, and Professional Dimensions.” Annual Review of Public Health 15 (1): 1–18.\n\n\nHu, Jingchen, and Claire McKay Bowen. 2024. “Advancing Microdata Privacy Protection: A Review of Synthetic Data Methods.” Wiley Interdisciplinary Reviews: Computational Statistics 16 (1): e1636.\n\n\nICPSR. n.d. “Guide to Social Science Data Preparation and Archiving: Best Practice Throughout the Data Life Cycle: 6th Edition.” https://www.icpsr.umich.edu/web/pages/deposit/guide/.\n\n\nMatthews, Gregory J, and Ofer Harel. 2011. “Data Confidentiality: A Review of Methods for Statistical Disclosure Limitation and Methods for Assessing Privacy.”\n\n\nMcClelland, Robert, Daniel Berger, Alyssa Harris, Chenxi Lu, and Kyle Ueyama. 2019. “The Tcja: What Might Have Been.” Urban-Brookings Tax Policy Center.\n\n\nMcKenna, L, and M Haubach. 2019. “Legacy Techniques and Current Research in Disclosure Avoidance at the Us Census Bureau.” Research and Methodology Directorate, US Census Bureau, Washington, DC.",
    "crumbs": [
      "Data Storage and Sharing",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Sharing and Transfer</span>"
    ]
  },
  {
    "objectID": "03_data-sharing-transfer.html#footnotes",
    "href": "03_data-sharing-transfer.html#footnotes",
    "title": "7  Data Sharing and Transfer",
    "section": "",
    "text": "“Federal Statistical Research Data Centers (FSRDCs) are partnerships between federal statistical agencies and leading research institutions. FSRDCs provide secure environments supporting qualified researchers using restricted-access data while protecting respondent confidentiality.” From the U.S. Census Bureau’s webpage on Federal Statistical Research Data Centers.↩︎\nThe National Science Foundation Secure Access Facility provides authorized researchers secure remote access to National Center for Science and Engineering Statistics data and metadata, such as the Survey of Earned Doctorates and the national Survey of Recent College Graduates.↩︎\n“An article written to inform readers about recent events. The author reports and attempts to deepen understanding of recent events—for example, by providing background information and other kinds of additional context.” – CSUSM Library↩︎",
    "crumbs": [
      "Data Storage and Sharing",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data Sharing and Transfer</span>"
    ]
  },
  {
    "objectID": "04_data-analysis-part1.html",
    "href": "04_data-analysis-part1.html",
    "title": "8  Data Analysis: Part 1",
    "section": "",
    "text": "8.1 Quick recap on week 3 (with some week 2)\nWe’ve discussed several challenges surrounding security, privacy, ethics, and equity in data collection, storage, and sharing.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data Analysis: Part 1</span>"
    ]
  },
  {
    "objectID": "04_data-analysis-part1.html#quick-recap-on-week-3-with-some-week-2",
    "href": "04_data-analysis-part1.html#quick-recap-on-week-3-with-some-week-2",
    "title": "8  Data Analysis: Part 1",
    "section": "",
    "text": "8.1.1 Data collection\nFor data collection, we learned the importance of:\n\nDeciding whether to collect the data or not.\nDefining groups and other variables that impacts our communities.\nRecognizing that a lack of data results in a lack of action.\n\n\n\n8.1.2 Data storage\nWe covered the following topics:\n\nThe overall process and considerations for cleaning data, especially how to handle missing data.\nBest practices for virtual and physical storage of data, including the FAIR principles for creating proper metadata.\n\nEven more definitions…\n\n\n\n\n\n\nOriginal dataset:\n\n\n\nOriginal dataset is the uncleaned, unprotected version of the data.\nFor example, raw 2020 Decennial Census microdata, which are never publicly released.\n\n\n\n\n\n\n\n\nConfidential or gold standard dataset\n\n\n\nConfidential or gold standard dataset is the cleaned version (meaning edited for inaccuracies or inconsistencies) of the data; often referred to as the gold standard or actual data for analysis.\nFor example, the Census Edited File that is the final confidential data for the 2020 Census. This dataset is never publicly released but may be made available to others who are sworn to protect confidentiality (i.e., Special Sworn Status) and who are provided access in a secure environment, such as a Federal Statistical Research Data Center.\n\n\n\n\n\n\n\n\nPublic dataset or statistics\n\n\n\nPublic dataset is the publicly released version of the confidential data.\nFor example, the US Census Bureau’s public tables and datasets or the Bureau of Labor Statistics reporting the unemployment rate statistics.\n\n\n\n\n8.1.3 Data sharing and transfer\nWe also learned about the two general ways people access data:\n\nSecure Data Access\n\nPros: Very secure, provides access to confidential data.\nCons: Inaccessible to most people.\n\nPublic Data Files and Statistics\n\nPros: Accessible to anyone.\nCons: Altered for privacy, which may reduce accuracy for specific applications and may not always be properly protected.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data Analysis: Part 1</span>"
    ]
  },
  {
    "objectID": "04_data-analysis-part1.html#what-is-the-privacy-utility-tradeoff",
    "href": "04_data-analysis-part1.html#what-is-the-privacy-utility-tradeoff",
    "title": "8  Data Analysis: Part 1",
    "section": "8.2 What is the privacy-utility tradeoff?",
    "text": "8.2 What is the privacy-utility tradeoff?\n\n\n\n\n\n\nData Utility\n\n\n\nData utility, quality, accuracy, or usefulness is how practically useful or accurate to the data are for research and analysis purposes.\n\n\nThere is often a tension between privacy and data utility. This tension is referred to in the privacy literature as the privacy-utility tradeoff.\n\n\n\n\n\n\nFigure 8.1: Generally, as privacy increases, the image quality (utility) decreases, and vice versa.\n\n\n\n\n\n\n\n\n\nClass Activity 1\n\n\n\nFor any data or digital information, what would be the best privacy protection? What would be the best way to ensure utility?",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data Analysis: Part 1</span>"
    ]
  },
  {
    "objectID": "04_data-analysis-part1.html#what-is-synthetic-data-why-use-it",
    "href": "04_data-analysis-part1.html#what-is-synthetic-data-why-use-it",
    "title": "8  Data Analysis: Part 1",
    "section": "8.3 What is synthetic data? Why use it?",
    "text": "8.3 What is synthetic data? Why use it?\n\n\n\n\n\n\nSynthetic Data\n\n\n\nSynthetic data consist of pseudo or “fake” records that are statistically representative of the confidential data.\n\n\n\nThe goal of most syntheses is to closely mimic the underlying distribution and statistical properties of the real data to preserve data utility while minimizing disclosure risks.\nSynthesized values also limit an intruder’s confidence, because they cannot confirm a synthetic value exists in the confidential dataset.\nSynthetic data may be used as a “training dataset” to develop programs to run on confidential data via a validation server.\n\n\n\n\n\n\n\nPartially synthetic\n\n\n\nPartially synthetic data only synthesizes some of the variables in the released data (generally those most sensitive to disclosure). In partially synthetic data, there remains a one-to-one mapping between confidential records and synthetic records.\n\n\nBelow, we see an example of what a partially synthesized version of confidential data could look like.\n\n\n\n\n\n\nFigure 8.2: Partially synthetic data\n\n\n\n\n\n\n\n\n\nFully synthetic\n\n\n\nFully synthetic data synthesizes all values in the dataset with imputed amounts. Fully synthetic data no longer directly map onto the confidential records, but remain statistically representative. Since fully synthetic data does not contain any actual observations, it protects against both attribute and identity disclosure.\n\n\nBelow, we see an example of what a fully synthesized version of confidential data might look like.\n\n\n\n\n\n\nFigure 8.3: Fully synthetic data\n\n\n\n\n\n\n\n\n\nThere are many flavors of synthetic data\n\n\n\nFor this course, we will focus only on fully and partially synthetic data. However, it is important to note that there are many other variations of synthetic data generation, such as Bayesian versus non-Bayesian synthesis models and parametric versus non-parametric models.\n\n\n\n8.3.1 Partial vs. fully synthetic advantages and disadvantages\n\nChanging only some variables (partial synthesis) in general leads to higher utility in analysis since the relationships between variables are by definition unchanged (Drechsler, Bender, and Rässler 2008).\nDisclosure in fully synthetic data is nearly impossible because all values are imputed, while partial synthesis has higher disclosure risk since confidential values remain in the dataset (Drechsler, Bender, and Rässler 2008).\n\nNote that while the risk of disclosure for fully synthetic data is very low, it is not zero.\n\nAccurate and exhaustive specification of variable relationships and constraints in fully synthetic data is difficult and if done incorrectly can lead to bias Drechsler, Bender, and Rässler (2008).\n\nIf a variable is synthesized incorrectly early in a sequential synthesis, all variables synthesized on the basis of that variable will be affected.\n\nPartially synthetic data may be publicly perceived as more reliable than fully synthetic data.\n\n\n\n\n\n\n\nClass Activity 2\n\n\n\nConsider this penguins data:\n\n\n\n\n\n\n\n\n\nspecies\nbill_length_mm\nsex\n\n\n\n\nChinstrap\n51.3\nmale\n\n\nGentoo\n44.0\nfemale\n\n\nChinstrap\n51.4\nmale\n\n\nChinstrap\n45.4\nfemale\n\n\nAdelie\n36.2\nfemale\n\n\n\n\n\n\n\n\nLet’s say that researchers decide that the sex of the penguins in the data are not confidential, but the species and bill length are. So, they develop regression models that predict species conditional on sex and predict bill_length conditional on species and sex. They then use those models to predict species and bill lengths for each row in the data and then release it publicly.\n\nQuestionSolution\n\n\nWhat specific SDC method are these researchers using?\n\n\nWhat specific SDC method are these researchers using?\nThey are using partially synthetic data.\n\n\n\n\n\n\n\n8.3.2 Why synthetic data?\nSynthetic data provides enhanced disclosure protection with a lower cost to utility than other “traditional” statistical disclosure control (SDC) methods. For example:\n\nMitra and Reiter (2006) found that a 5 percent swapping of 2 identifying variables in the 1987 Survey of Youth in Custody invalidated statistical hypothesis tests in regression.\nTop/bottom coding eliminates information at the tails of the distributions, degrading analyses that depend on the entire distribution (Reiter, Wang, and Zhang 2014).\n\nIt also allows for release of data that is more disaggregated than might otherwise be possible with “traditional” SDC (aggregation is a very common SDC technique).",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data Analysis: Part 1</span>"
    ]
  },
  {
    "objectID": "04_data-analysis-part1.html#data-synthesis-process-overview",
    "href": "04_data-analysis-part1.html#data-synthesis-process-overview",
    "title": "8  Data Analysis: Part 1",
    "section": "8.4 Data Synthesis Process Overview",
    "text": "8.4 Data Synthesis Process Overview\nNote that this overview is opinionated and simplified in order to provide a reasonable summary.\n\n\n\n\n\n\nFigure 8.4: The synthesis process is very iterative, particularly in the privacy step\n\n\n\n\n8.4.1 Privacy stakeholders and the synthesis process\n\n\n\n\n\n\nFigure 8.5: All of the privacy stakeholders discussed previously have a role in aspects of the synthesis process\n\n\n\n\n\n\n\n\n\nWhy synthetic data and not the other SDC methods?\n\n\n\nI wanted to review at least one Statistical Disclosure Control (SDC) method in depth to provide further context on how to evaluate public data files. Additionally, with the increasing prominence of AI, many researchers and public policymakers are proposing the use of synthetic data generation in combination with AI. It is important to be aware of such a technique, as it is likely to become more popular in the future.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data Analysis: Part 1</span>"
    ]
  },
  {
    "objectID": "04_data-analysis-part1.html#assessing-utility",
    "href": "04_data-analysis-part1.html#assessing-utility",
    "title": "8  Data Analysis: Part 1",
    "section": "8.5 Assessing utility",
    "text": "8.5 Assessing utility\nGenerally there are three ways to measure utility of the data:\n\nGeneral (or global) utility metrics;\nSpecific utility metrics; and\nFit-for-purpose\n\n\n8.5.1 General utility metrics\n\n\n\n\n\n\nGeneral utility\n\n\n\nGeneral utility, sometimes called global utility, measures the univariate and multivariate distributional similarity between the confidential data and the public data (e.g., sample means, sample variances, and the variance-covariance matrix).\n\n\nGeneral utility metrics are useful because they provide a sense of how “fit for use” synthetic data is for analysis without making assumptions about the uses of the synthetic data.\n\nUnivariate general utility\nSome univariate general utility measures could include comparisons of:\n\nCategorical variables: frequencies, relative frequencies.\nNumeric variables means, standard deviations, skewness, kurtosis (i.e., first four moments), percentiles, and number of zero/non-zero values.\n\n\n\nBivariate general utility\n\n\n\n\n\n\nCorrelation fit\n\n\n\nCorrelation fit measures how well the synthesizer recreates the linear relationships between variables in the confidential dataset.\n\n\nTo calculate correlation fit:\n\nCreate correlation matrices for the synthetic data and confidential data. Then measure differences across synthetic and actual data.\n\n\n\n\n\n\n\nFigure 8.6: Correlation Difference\n\n\n\nFigure 8.6 shows the creation of a difference matrix. Let’s summarize the difference matrix using mean absolute error.\n\n\nMultivariate general utility (discriminant-based metrics)\n\n\n\n\n\n\nDiscriminant based methods\n\n\n\nDiscriminant based methods measure how well a predictive model can distinguish (i.e., discriminate) between records from the confidential and synthetic data.\n\n\n\nThe confidential data and synthetic data should theoretically be drawn from the same super population.\nThe basic idea is to combine (stack) the confidential data and synthetic data and see how well a predictive model distinguish (i.e., discriminate) between synthetic observations and confidential observations.\nAn inability to distinguish between the records suggests a good synthesis.\nIt is possible to use logistic regression for the predictive modeling, but decision trees, random forests, and boosted trees are more common. (We recommend, to the degree possible, using more using more sophisticated models as well as machine learning best-practices like feature engineering and hyperparameter tuning because these practices will more effectively discriminate between classes.)\nFigure 8.7 shows three discriminant based metrics calculated on a good synthesis and a poor synthesis.\n\n\n\n\n\n\n\n\n\nGood Synthesis\n\n\n\n\n\n\n\n\n\nPoor Synthesis\n\n\n\n\n\n\nFigure 8.7: A comparison of discriminant metrics on a good synthesis and a poor synthesis\n\n\n\nThere are several different discriminant-based metrics, but it is beyond this course to cover them in depth. Hu and Bowen (2024) covers these metrics in further detail.\n\n\n\n8.5.2 Specific utility metrics\n\n\n\n\n\n\nSpecific utility\n\n\n\nSpecific utility, sometimes called outcome specific utility, measures the similarity of results for a specific analysis (or analyses) of the confidential and public data (e.g., comparing the coefficients in regression models).\n\n\nSpecific utility metrics measure how suitable a synthetic dataset is for specific analyses.\n\nThese specific utility metrics will change from application to application, depending on common uses of the data.\nA helpful rule of thumb: general utility metrics are useful for the data synthesizers to be convinced that they’re doing a good job. Specific utility metrics are useful to convince downstream data users that the data synthesizers are doing a good job.\n\n\nRecreating inferences\n\nIt can be useful to compare statistical analyses on the confidential data and synthetic data:\n\nDo the estimates have the same sign?\nDo the estimates have the same statistical inference at a common significance level?\nDo the confidence intervals for the estimates overlap?\n\nEach of these questions is useful. Barrientos et al. (2024) combine all three questions into sign, significance, and overlap (SSO) match. SSO is the proportion of times that intervals overlap and have the same sign and significance.\n\n\n\nRegression confidence interval overlap\n\n\n\n\n\n\nRegression confidence interval overlap\n\n\n\nRegression confidence interval overlap quantifies how well confidence intervals from estimates on the synthetic data recreate confidence intervals from the confidential data.\n1 indicates perfect overlap (it is typically impossible to achieve a 1 on real-world data). 0 indicates intervals that are adjacent but not overlapping. Negative values indicate gaps between the intervals.\nIt is common to compare intervals from linear regression models and logistic regression models.\n\n\n\n\n\nConfidence interval overlap as a measure of specific utility\n\n\n\n\n\n8.5.3 Fit-for-purpose\nThe final group of utility metrics are called fit-for-purpose and are not discussed as often in the literature. Drechsler (2022) states how fit-for-purpose measures could be considered something in between the previous two utility metric types. In other words, fit-for-purpose metrics are not global measures, because they focus on certain features of the data, but may not be specific to an analysis that data users and stakeholders are interested in like analysis-specific utility metrics.\nDrechsler (2022) highlights how global utility metrics can be too broad and miss aspects of the synthetic dataset that do not align with the confidential dataset. On the other hand, analysis-specific metrics may perform well for the selected analyses on the synthetic data but not for others. This is why it is critical to determine the proper analysis, but it is difficult to anticipate all downstream data uses. For example, Decennial Census data products in the United States are utilized in thousands of different ways, making it impossible to predict all potential use cases. Therefore, fit-for-purpose metrics help privacy experts and researchers assess if their synthesis makes sense before implementing other utility metrics. Some examples include ensuring population totals or ages are positive.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data Analysis: Part 1</span>"
    ]
  },
  {
    "objectID": "04_data-analysis-part1.html#assessing-disclosure-risk",
    "href": "04_data-analysis-part1.html#assessing-disclosure-risk",
    "title": "8  Data Analysis: Part 1",
    "section": "8.6 Assessing disclosure risk",
    "text": "8.6 Assessing disclosure risk\nWe now pivot to evaluating the disclosure risks of synthetic data. Note that most thresholds for acceptable disclosure risk are often determined by law.\nThere are generally three kinds of disclosure risk:\n\nIdentity disclosure risk;\nAttribute disclosure risk; and\nInferential disclosure risk.\n\n\n\n8.6.1 Identity disclosure metrics\n\n\n\n\n\n\nIdentity disclosure\n\n\n\nIdentity disclosure occurs if the data intruder associates a known individual with a public data record (e.g., a record linkage attack or when a data adversary combines one or more external data sources to identify individuals in the public data).\n\n\nSweeney, Abu, and Winn (2013) used voter data to re-identify individuals in the Personal Genome Project.\n\n\n\n\n\n\nFigure 8.8: Record linkage attack\n\n\n\nFor fully synthetic datasets, there is no one to one relationship between individuals and records so identity disclosure risk is ill-defined. Generally identity disclosure risk applies to partially synthetic datasets (or datasets protected with traditional SDC methods).\n\n\n\n\n\n\nIdentity disclosure metrics\n\n\n\nIdentity disclosure metrics evaluate how often we correctly re-identify confidential records in the synthetic data.\nNote: These metrics require major assumptions about attacker information.\n\n\n\nBasic matching approaches\n\nWe start by making assumptions about the knowledge an attacker has (i.e., external publicly accessible data they have access to).\nFor each confidential record, the data attacker identifies a set of partially synthetic records which they believe contain the target record (i.e., potential matches) using the external variables as matching criteria.\nThere are distance-based and probability-based algorithms that can perform this matching. This matching process could be based on exact matches between variables or some relaxations (i.e., matching continuous variables within a certain radius of the target record, or matching adjacent categorical variables).\nWe then evaluate how accurate our re-identification process was using a variety of metrics.\n\n\nExpected Match RateTrue Match RateFalse Match Rate\n\n\n\nExpected Match Rate: On average, how likely is it to find a “correct” match among all potential matches? Essentially, the expected number of observations in the confidential data expected to be correctly matched by an intruder.\n\nHigher expected match rate = higher identification disclosure risk.\nThe two other risk metrics below focus on the subset of confidential records for which the intruder identifies a single match.\n\n\n\n\n\nTrue Match Rate: The proportion of true unique matches among all confidential records. Higher true match rate = higher identification disclosure risk.\n\n\n\n\nFalse Match Rate: The proportion of false matches among the set of unique matches. Lower false match rate = higher identification disclosure risk.\n\n\n\n\n\n\n\n\n\n\nClass Activity 3\n\n\n\n\nQuestionAnswer\n\n\nA researcher has confidential data on a population. To protect the privacy of respondents, the researcher releases a synthetic version of the data. A data attacker then runs a record linkage attack against the synthetic data and is able to accurately identify 5 individuals in the data. Based on this information, can you tell whether the researcher released fully or partially synthetic data? Why or why not?\n\n\nA researcher has confidential data on a population. To protect the privacy of respondents, the researcher releases a synthetic version of the data. A data attacker then runs a record linkage attack against the synthetic data and is able to accurately identify 5 individuals in the data. Based on this information, can you tell whether the researcher released fully or partially synthetic data? Why or why not?\nRecord linkage attacks are only possible for partially synthetic data, though other types of disclosure risk still apply to fully synthetic data.\n\n\n\n\n\n\n\n\n8.6.2 Attribute disclosure metrics\nIt is possible to learn confidential attributes without perfectly re-identifying observations in the data.\n\n\n\n\n\n\nAttribute disclosure\n\n\n\nAttribute disclosure occurs if the data intruder determines new characteristics (or attributes) of an individual based on the information available through public data or statistics (e.g., if a dataset shows that all people age 50 or older in a city are on Medicaid, then the data adversary knows that any person in that city above age 50 is on Medicaid). This information is learned without idenfying a specific individual in the data!\n\n\n\n\n\n\n\n\nPredictive Accuracy\n\n\n\nPredictive accuracy measures how well an attacker can learn about attributes in the confidential data using the synthetic data (and possibly external data).\n\n\n\nSimilar to above, you start by matching synthetic records to confidential records. Alternatively, you can build a predictive model using the synthetic data to make predictions on the confidential data.\nkey variables: Variables that an attacker already knows about a record and can use to match.\ntarget variables: Variables that an attacker wishes to know more or infer about using the synthetic data.\nPick a sensitive variable in the confidential data and use the synthetic data to make predictions. Evaluate the accuracy of the predictions.\n\n\n\n8.6.3 Inferential disclosure\n\n\n\n\n\n\nInferential disclosure\n\n\n\nInferential disclosure occurs if the data intruder predicts the value of some characteristic from an individual more accurately with the public data or statistic than would otherwise have been possible (e.g., if a public homeownership dataset reports a high correlation between the purchase price of a home and family income, a data adversary could infer another person’s income based on purchase price listed on Redfin or Zillow).\n\n\nInferential disclosure is a specialized type of attribute disclosure, so the metrics discussed above apply here as well. Inference disclosure risk is very hard to predict, so many federal agencies tend to disregard this type of risk.\n\n\n\n\n\n\nClass Activity 4\n\n\n\nLast week, one of the class activities asked about how to protect a K-12 education dataset that dataset contains information about all students in a state, specifically their names, ages, genders, home addresses, and standardized test scores. Suppose wyou use fully synthetic data generation.\n\nWhat would be the potential identity disclosure risks?\nWhat would be the potential attribute disclosure risks?\nWhat would be the potential inferential disclosure risks?\n\n\n\n\n\n\n\nBarrientos, Andrés F, Aaron R Williams, Joshua Snoke, and Claire McKay Bowen. 2024. “A Feasibility Study of Differentially Private Summary Statistics and Regression Analyses with Evaluations on Administrative and Survey Data.” Journal of the American Statistical Association 119 (545): 52–65.\n\n\nDrechsler, Jörg. 2022. “Challenges in Measuring Utility for Fully Synthetic Data.” In International Conference on Privacy in Statistical Databases, 220–33. Springer.\n\n\nDrechsler, Jörg, Stefan Bender, and Susanne Rässler. 2008. “Comparing Fully and Partially Synthetic Datasets for Statistical Disclosure Control in the German IAB Establishment Panel.” Transactions on Data Privacy 1 (December): 105–30.\n\n\nHu, Jingchen, and Claire McKay Bowen. 2024. “Advancing Microdata Privacy Protection: A Review of Synthetic Data Methods.” Wiley Interdisciplinary Reviews: Computational Statistics 16 (1): e1636.\n\n\nMitra, Robin, and Jerome P Reiter. 2006. “Adjusting Survey Weights When Altering Identifying Design Variables via Synthetic Data.” In Privacy in Statistical Databases: CENEX-SDC Project International Conference, PSD 2006, Rome, Italy, December 13-15, 2006. Proceedings, 177–88. Springer.\n\n\nReiter, Jerome P, Quanli Wang, and Biyuan Zhang. 2014. “Bayesian Estimation of Disclosure Risks for Multiply Imputed, Synthetic Data.” Journal of Privacy and Confidentiality 6 (1).\n\n\nSweeney, Latanya, Akua Abu, and Julia Winn. 2013. “Identifying Participants in the Personal Genome Project by Name (a Re-Identification Experiment).” https://arxiv.org/abs/1304.7605.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Data Analysis: Part 1</span>"
    ]
  },
  {
    "objectID": "04_better-presentations.html",
    "href": "04_better-presentations.html",
    "title": "9  Better Presentations",
    "section": "",
    "text": "9.1 Your final\nVerbal communication is crucial in most professions and is often not taught in courses. From this final, my hope is you will learn more how to create better presentations and how to present more technical content to a broader audience. The goal of this final is to develop and deliver a clear, concise, and engaging presentation on a topic of your choice within a strict 5-minute time limit, but your target audience will be randomized. This exercise will help you improve your research, organization, and public speaking skills.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Better Presentations</span>"
    ]
  },
  {
    "objectID": "04_better-presentations.html#your-final",
    "href": "04_better-presentations.html#your-final",
    "title": "9  Better Presentations",
    "section": "",
    "text": "9.1.1 Evaluation of the presentation\nThe following is how I will evaluate your presentations. Each part will be scored from 1 to 10, as detailed below.\n\nContent and audience (10 points)\n\n10: Clear purpose and content that addresses the target audience.\n5: Moderate clarity and relevance to the target audience.\n1: Unclear purpose and irrelevant to the target audience.\n\nOrganization and structure (10 points)\n\n10: Well-organized with a clear and strong flow (introduction, middle, and conclusion).\n5: Moderately organized with adequate flow.\n1: Poorly organized, missing key structural elements.\n\nDelivery and timing (10 points)\n\n10: Enthusiastic and engaging, with good pacing, within 30 seconds of the time limit.\n5: Some enthusiasm and minor pacing issues, within 30 seconds to 1 minute of the time limit.\n1: Lacks enthusiasm, poor pacing, over 1 minute off the time limit.\n\nQuality of slides or other visual aids (10 points)\n\n10: Enhances the presentation.\n5: Somewhat contributes to the presentation.\n1: Does not contribute to the presentation.\n\nOverall quality (10 points)\n\n10: Highly effective in achieving the goal.\n5: Somewhat effective in achieving the goal.\n1: Ineffective in achieving the goal.\n\n\n\n\n\n\n\n\nGrading will be generous\n\n\n\nPublic speaking remains one of the top fears among people in the United States. Becoming a good public speaker requires a lot of practice. Yet, even with extensive practice, some people may struggle to become compelling and engaging speakers.\nThe purpose of this final is to help you achieve 90% of the goal by ensuring your slides and content are well-organized. In other words, as long as your presentation is well-organized and thoughtfully prepared, you will receive a minimum grade of A- (90%). The remaining 10% depends on your execution.\n\n\n\n\n9.1.2 Your choice of topic, but first come first serve\nThe topic can be anything you learned in class today. It can be on something you wrote, in class discussion, contents in the book or other materials you read/watched, as long as it relates back to security, privacy, ethics, and equity. To avoid repeated talks, you must email me your topic by June 21. I will let you know if you’re the first to propose the topic, so you should come up with a few different topics just in case your top pick has already been taken.\n\n\n9.1.3 Randomize target audience\n\nset.seed(42)\n\nlibrary(tidyverse)\n\nstudents &lt;- c(\"Black\", \"Boes\", \"Cohen\", \"Coleman\", \"DeAngelo\", \"Duff\", \n              \"Flynn\", \"Gomez\", \"Keohane\", \"Kiely\", \"Larsson\", \"Lombardi\",\n              \"Macro\", \"Mathews\", \"Meslin\", \"Norton\", \"Novakoski\",\n              \"Russell\", \"Schreifels\", \"Scully\", \"Sokolova\", \"Weir\",\n              \"Williams\")\n\nn &lt;- length(students)\n\naudience &lt;- c(\"family-friends\", \"undergraduates-coworkers\",\n              \"funders-media\", \"government-policymaker\")\n\naudience %&gt;%\n  sample(., n, replace = TRUE) %&gt;%\n  bind_cols(students, .) %&gt;%\n  print(n = n)\n\n# A tibble: 23 × 2\n   ...1       ...2                    \n   &lt;chr&gt;      &lt;chr&gt;                   \n 1 Black      family-friends          \n 2 Boes       family-friends          \n 3 Cohen      family-friends          \n 4 Coleman    family-friends          \n 5 DeAngelo   undergraduates-coworkers\n 6 Duff       government-policymaker  \n 7 Flynn      undergraduates-coworkers\n 8 Gomez      undergraduates-coworkers\n 9 Keohane    family-friends          \n10 Kiely      government-policymaker  \n11 Larsson    funders-media           \n12 Lombardi   government-policymaker  \n13 Macro      funders-media           \n14 Mathews    government-policymaker  \n15 Meslin     family-friends          \n16 Norton     family-friends          \n17 Novakoski  undergraduates-coworkers\n18 Russell    government-policymaker  \n19 Schreifels undergraduates-coworkers\n20 Scully     undergraduates-coworkers\n21 Sokolova   funders-media           \n22 Weir       funders-media           \n23 Williams   family-friends",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Better Presentations</span>"
    ]
  },
  {
    "objectID": "04_better-presentations.html#better-presentations",
    "href": "04_better-presentations.html#better-presentations",
    "title": "9  Better Presentations",
    "section": "9.2 Better presentations",
    "text": "9.2 Better presentations\nMany of the information and example slides provided here were created by my colleague, Jon Schwabish, a senior fellow at the Urban Institute and an author of several books on data visualization and communication. I’ve also added a few personal tips.\n\n9.2.1 Designing your presentation\n\nDon’t race to your computer\nOutline, sketch (use post-its and index cards)\n\n\n\n\n\n\n\nFigure 9.1: Designing your presentation image from Jon Schwabish.\n\n\n\n\nThe Hourglass structure\nTypically, the presentation structure is as follows, resembling a pyramid in terms of content and time:\n\nIntroduction\nPrevious literature\nData\nMethods\nResults\nConclusions\n\nHowever, it should be more like an hourglass. You want to spend more time getting people hooked at the beginning and then dedicate more time on the conclusions and takeaway at the end.\n\n\n\n\n\n\nFigure 9.2: Hourglass presentation structure.\n\n\n\n\n\nPresentation worksheet\nThe presentation worksheet helps you organize your presentation. It involves the following:\n\nWhat types of presentation are you giving?\nWho is your audience?\nWhat is the headline message of your presentation?\nWhat do you want your audience to do with your conclusions?\nCraft your opening statement.\nCraft your closing statement\nOutline the sections of your presentation.\nWhat stories can you tell?\nImages (sketch or describe before searching).\nAnticipated Q&A.\n\n\n\nResources\nJon provided materials that he mentions in his book, “Better Presentations: A Guide for Scholars, Researchers, and Wonks” for free on his website. The materials include:\n\nBetter Presentations Supplies Checklist\nBetter Presentations Worksheet\nColor Palettes\nGrids\nHeader Slides\nIcons\nTitle Slides\nReferences\n\n\n\n\n9.2.2 Building your presentation\n\nText slides\n\nSlides are not a document\nSlides are free\nLayer your slides\n“The more visual the input becomes, the more likely it is to be recognized and recalled.” John Medina, Brian Rules.\nSlides should be visual\nSpell check and copyedit\n\n\nText slides: Example 1\n  \n\n\nText slides: Example 2\n\n\n\n\n\n\nFigure 9.3: Outlook for the Federal Budget highlight content 1.\n\n\n\n\n\n\n\n\n\nFigure 9.4: Outlook for the Federal Budget highlight content 2.\n\n\n\n\n\n\n\n\n\nFigure 9.5: Outlook for the Federal Budget highlight content 3.\n\n\n\n\n\n\n\n\n\nFigure 9.6: Federal Health Care Spending is Projected to Rise Quickly.\n\n\n\n\n\n\n\n\n\nFigure 9.7: Growth is Even Faster with Health Care & Social Security.\n\n\n\n\n\n\n\n\n\nFigure 9.8: All Other Federal Spending Grew Slightly Faster Over Past 40 years.\n\n\n\n\n\n\nData visualization slides\n\nMake your point clear\nOne chart per slide\nMore layers\n\n\nText slides: Example\n\n\n\n\n\n\nFigure 9.9: Education opener.\n\n\n\n\n\n\n\n\n\nFigure 9.10: Tuition and fees vary by nearly $30k.\n\n\n\n\n\n\n\n\n\nFigure 9.11: Room and board is highest for four-year private schools.\n\n\n\n\n\n\n\n\n\nFigure 9.12: Books and supplies are about the same across all schools.\n\n\n\n\n\n\n\n\n\nFigure 9.13: Transportation costs are higher for commuter schools.\n\n\n\n\n\n\n\n\n\nFigure 9.14: Other costs are highest for commuter schools.\n\n\n\n\n\n\n\n\n\nFigure 9.15: Total costs are driven by differences in tuition.\n\n\n\n\n\n\nTable slide\n\nLayer your slides\nConvert the content to the core ideas\n\n \n\n\n\n\n\n\nFigure 9.16: Table version 3.\n\n\n\n\n\n\n\n\n\nFigure 9.17: Table version 4.\n\n\n\n\n\n\n9.2.3 Giving your presentation\n\nPractice, practice, practice\nBe cognizant of time\nAvoid standing behind a podium (if possible)\nDon’t face the screen (look at the audience)\nShare your slides with others\nUse the notes pane\nBe enthusiastic (is possible)",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Better Presentations</span>"
    ]
  },
  {
    "objectID": "04_better-presentations.html#a-real-5-minute-pitch",
    "href": "04_better-presentations.html#a-real-5-minute-pitch",
    "title": "9  Better Presentations",
    "section": "9.3 A real 5-minute pitch",
    "text": "9.3 A real 5-minute pitch\n\nOur focus will be on engaging trustees in our strategic planning process. As a precursor to strategic planning, we want to illustrate the various kinds of work that Urban does today that trustees can understand our theory of change before diving into big strategy thinking. Therefore, we are planning a content segment titled “Understanding Urban’s Work”, where five experts would present on concrete examples of different types of Urban’s work and how we bring insight from evidence to point of decision, to help changemakers accelerate solutions.\nEach presentation would be about five minutes long, followed by seven minutes of questions and/or discussion by trustees. Donald Marron has agreed to moderate the segment and facilitate the presentations and respective Q&A. Would you be willing to present on the IRS Data and Validation Server project and how it makes an impact?\n\nWhat type of presentation are you giving?: A 5-minute presentation.\nWho is your audience?: Urban Institute’s Board of Trustees, diverse technical backgrounds, but all interested in evidence-based public policymaking.\nWhat is the headline message of your presentation?: Advance the promise of more evidence-based public policymaking using administrative data.\nWhat do you want your audience to do with your conclusion?: To continue to support data science and data privacy methods to safely expand access to confidential administrative data.\n\n\n\n\n\n\nFigure 9.18: Title page\n\n\n\nI’m excited to be presenting on the Urban Institute’s collaboration with the IRS to advance the promise of more evidence-based public policymaking.\n\n9.3.1 Slide 1\n\n\n\n\n\n\nFigure 9.19: Slide 1\n\n\n\nFederal tax data, derived from individuals’ and businesses’ tax and information returns, are invaluable resources for understanding the economic effects of policies, social and economic forces, and more on individuals, families, and firms.\n\n\n9.3.2 Slide 2\n\n\n\n\n\n\nFigure 9.20: Slide 2\n\n\n\nFor example, Raj Chetty and colleagues have used tax data to study economic mobility across generations and how elementary school teacher quality affects economic outcomes later in life. However, full access to these data are only available to select government agencies, a very limited number of researchers working in collaboration with analysts in those agencies, or through highly selective research programs run by these agencies.\nSo, how can we expand access to administrative tax data to other researchers, government officials, and public policymakers instead of the select few like Raj Chetty? This is where our team comes in. We are developing new data science tools to allow researchers access to sensitive data while providing more robust privacy protection. This new technology can also be applied to other administrative data!\nNow is the ideal time to develop such new technology and methodology as the Evidence Act commits the federal government to expand access to data along with Biden’s executive order, directing federal agencies and White House offices to examine barriers to racial equity and initiate several efforts to address equity for people of color and underserved communities. Furthermore, Len Burman, an institute fellow and co-PI on this body of work, is a member of the Advisory Committee on Data for Evidence Building, which Urban is supporting with internal funds.\n\n\n9.3.3 Slide 3\n\n\n\n\n\n\nFigure 9.21: Slide 3\n\n\n\nSo, how does our data science tools work to allow access to data? Typically, researchers access data in two ways, direct access to the confidential data or public statistics and data. However, direct access is difficult due to clearance or eligibility issues, such as being a US citizen. Public statistics and data aren’t much better either. Awareness of the growing threats to public use microdata and a general concern for protecting participants’ data privacy have led the IRS to progressively restrict and distort more information being released in their public statistics and data, making the information less useful for academic research and policy analysis.\nWith our data science tools, we are improving the quality of the public data and creating a new tier in-between these two extremes.\n\nInsert explainer on how these privacy protecting tools works with the art example.\nNote that we are also looking into including demographic information in datasets so we can analyze disparate impacts of policies by race and ethnicity.\nWhen comparing the original Seurat painting, we can still see figures in the park.\n\n\n\n9.3.4 Slide 4\n\n\n\n\n\n\nFigure 9.22: Slide 4\n\n\n\nHowever, sometimes our alterations to the data can be too much. For example, many people would say the resulting painting would not be a Seurat painting! Or you smoothed out the high income individuals that I wanted to analyze!\n\nInsert explainer on how these privacy protecting tools works with the art example again for the validation server.\n\nWe expect our tools to become critical components of the federal, state, and local data infrastructure. For example, our tools are the basis for creating synthetic data tools and educational materials for the city of Pittsburgh. We are also engaging with Congressional Budget Office, Environmental Protection Agency, Joint Committee on Taxation, Duke University, and American Enterprise Institute to name a few.\n\n\n9.3.5 Slide 5\n\n\n\n\n\n\nFigure 9.23: Slide 5\n\n\n\nHow we are supporting this impactful work? Thanks to these entities, we have fundraised over $5 million. This demonstrates how our body of work has become a big growth area for the Urban Institute. We are breaking ground in the intersection of data privacy and public policy that is providing more evidence-based research, which has been Urban’s business since its founding. I cannot emphasize enough that we are advancing this mission more than ever, where we are becoming the leaders in this area by creating unprecedent access to administrative data to make these better public policy decision-making.",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Better Presentations</span>"
    ]
  },
  {
    "objectID": "04_data-analysis-part2.html",
    "href": "04_data-analysis-part2.html",
    "title": "10  Data Analysis: Part 2",
    "section": "",
    "text": "10.1 This part of the course is still under construction! To be added by June 14, 2024. Proceed with caution!",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Data Analysis: Part 2</span>"
    ]
  },
  {
    "objectID": "04_data-analysis-part2.html#this-part-of-the-course-is-still-under-construction-to-be-added-by-june-14-2024.-proceed-with-caution",
    "href": "04_data-analysis-part2.html#this-part-of-the-course-is-still-under-construction-to-be-added-by-june-14-2024.-proceed-with-caution",
    "title": "10  Data Analysis: Part 2",
    "section": "",
    "text": "Figure 10.1: Webpage under construction!",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Data Analysis: Part 2</span>"
    ]
  },
  {
    "objectID": "04_data-analysis-part2.html#hiding-the-real-data-story",
    "href": "04_data-analysis-part2.html#hiding-the-real-data-story",
    "title": "10  Data Analysis: Part 2",
    "section": "10.2 Hiding the real data story",
    "text": "10.2 Hiding the real data story\nFrom the required reading, we learned that we must carefully take into account how the data are collected, analyzed, disseminated. If we don’t, we risk missing a vital piece of the data story, especially when data sets are aggregated, and cause more unintended harm to those we are trying to protect.\nFor your assignment this week, you had to find a news analysis story1 published within the last year (2023 – present).\n\n\n\n\n\n\nClass Activity 1\n\n\n\nDescribe the news analysis story you wrote about for your writing assignment and discuss the following questions:\n\nHow do the claims made in the article apply to your life, family, or community?\nWho authored the article, and how might their background influence its content?\nDo you have any doubts or concerns about the contents in the article? If so, what are they?\nHow could the story change with an increase or decrease in available data?",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Data Analysis: Part 2</span>"
    ]
  },
  {
    "objectID": "04_data-analysis-part2.html#give-me-the-real-stats",
    "href": "04_data-analysis-part2.html#give-me-the-real-stats",
    "title": "10  Data Analysis: Part 2",
    "section": "10.3 Give me the real stats!",
    "text": "10.3 Give me the real stats!\n\n\n\n\n\n\nClass Activity 2\n\n\n\nYou will be given 30 minutes (check in on progress at 15 minutes) to complete this in-class activity.\nEach of you have been assigned a random “fact” (see table below).\nFor your assigned question, come up with at least two different statistics that are technically correct but seem to contradict each other based on the United States. For each statistic, answer the following:\n\nWhat information did you use to answer your question?\nDid the digital object that contained the information follow the FAIR principles?\nHow did you access that information?\n\nWas the storage and transfer of that information consider security and privacy?\n\nHow did you use that information to answer your question?\nDo you have any ethical and/or equity concerns about this information?\n\n\n\nTopic assignments:\n\n\n\n\n\n\n\nStudent Last Name\nTopic\n\n\n\n\nBlack\nWhat percent of marriages end in divorce?\n\n\nBoes\nWhat is the percentage of African American men incarcerated compared to those in college?\n\n\nCohen\nWhat is the carbon footprint of raising a child?\n\n\nColeman\nWhat is the gender pay gap?\n\n\nDeAngelo\nAt what age are women less likely to get pregnant?\n\n\nDuff\nWhat is the average student loan debt?\n\n\nFlynn\nWhat is the rate of illegal immigration?\n\n\nGomez\nWhat is the primary factor that causes homelessness?\n\n\nKeohane\nWhat is the rate of sexual assault?\n\n\nKiely\nAt what age do mental health disorders develop in people?\n\n\nLarsson\nWhat is the teenage pregnancy rate?\n\n\nLombardi\nAt what year after being founded do most startup companies fail?\n\n\nMacro\nWhat percentage of immigrants are taking jobs from Americans?\n\n\nMathews\nWhat is the average cost of raising a child?\n\n\nMeslin\nWhat percentage of crimes are committed by someone known to the victim?\n\n\nNorton\nWhat percentage of welfare recipients are able-bodied adults who don’t work?\n\n\nNovakoski\nWhat is the fraud rate of using food stamps?\n\n\nRussell\nDoes the unemployment rate accurately reflect joblessness?\n\n\nSchreifels\nWhat percentage of immigrants are undocumented?\n\n\nScully\nWhat is the percentage of abortions performed on teenagers?\n\n\nSokolova\nWhat is the percentage of gun violence?\n\n\nWeir\nWhat percentage of energy consumption comes from renewable sources?\n\n\nWilliams\nWhat is the percentage of voter fraud?",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Data Analysis: Part 2</span>"
    ]
  },
  {
    "objectID": "04_data-analysis-part2.html#week-5-assignment",
    "href": "04_data-analysis-part2.html#week-5-assignment",
    "title": "10  Data Analysis: Part 2",
    "section": "10.4 Week 5 Assignment",
    "text": "10.4 Week 5 Assignment\n\n\n\n\n\n\nDEADLINE\n\n\n\nDue June 20, at 11:59 PM EDT on Canvas\n\n\n\n10.4.1 Read\n\nChapter 6: What Data Privacy Laws Exist?\n\n\n\n10.4.2 Optional additional read\n\nDo No Harm Guide: Applying Equity Awareness in Data Visualization.\n\n\n\n10.4.3 Collect data\nFor one day, record how often private companies collect your data from the moment you wake up to the moment you go to bed. For example, opening a social media app or browsing the web.\n\n\n10.4.4 Write (600 to 1200 words)\nBased on your data log, answer the following questions:\n\nIs any of the information collected by private companies protected by a state or federal law?\nWhat could a private company do with that information for the public good?\nWhat could a private company do with that information that may harm or violate your personal privacy?\nWhat are the data equity and ethical impacts of collecting this information?",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Data Analysis: Part 2</span>"
    ]
  },
  {
    "objectID": "04_data-analysis-part2.html#footnotes",
    "href": "04_data-analysis-part2.html#footnotes",
    "title": "10  Data Analysis: Part 2",
    "section": "",
    "text": "“An article written to inform readers about recent events. The author reports and attempts to deepen understanding of recent events—for example, by providing background information and other kinds of additional context.” – CSUSM Library↩︎",
    "crumbs": [
      "Data Analysis",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Data Analysis: Part 2</span>"
    ]
  },
  {
    "objectID": "05_data-dissemination-part1.html",
    "href": "05_data-dissemination-part1.html",
    "title": "11  Data Dissemination: Part 1",
    "section": "",
    "text": "11.1 This part of the course is still under construction! To be added by June 21, 2024. Proceed with caution!",
    "crumbs": [
      "Data Dissemination",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Data Dissemination: Part 1</span>"
    ]
  },
  {
    "objectID": "05_data-dissemination-part1.html#this-part-of-the-course-is-still-under-construction-to-be-added-by-june-21-2024.-proceed-with-caution",
    "href": "05_data-dissemination-part1.html#this-part-of-the-course-is-still-under-construction-to-be-added-by-june-21-2024.-proceed-with-caution",
    "title": "11  Data Dissemination: Part 1",
    "section": "",
    "text": "Figure 11.1: Webpage under construction!",
    "crumbs": [
      "Data Dissemination",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Data Dissemination: Part 1</span>"
    ]
  },
  {
    "objectID": "05_communication-collaboration-culture.html",
    "href": "05_communication-collaboration-culture.html",
    "title": "12  Communication, Collaboration, and Culture (Or Class Choice)",
    "section": "",
    "text": "12.1 This part of the course is still under construction! To be added by June 21, 2024. Proceed with caution!",
    "crumbs": [
      "Data Dissemination",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Communication, Collaboration, and Culture (Or Class Choice)</span>"
    ]
  },
  {
    "objectID": "05_communication-collaboration-culture.html#this-part-of-the-course-is-still-under-construction-to-be-added-by-june-21-2024.-proceed-with-caution",
    "href": "05_communication-collaboration-culture.html#this-part-of-the-course-is-still-under-construction-to-be-added-by-june-21-2024.-proceed-with-caution",
    "title": "12  Communication, Collaboration, and Culture (Or Class Choice)",
    "section": "",
    "text": "Figure 12.1: Webpage under construction!",
    "crumbs": [
      "Data Dissemination",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Communication, Collaboration, and Culture (Or Class Choice)</span>"
    ]
  },
  {
    "objectID": "05_communication-collaboration-culture.html#collaboration",
    "href": "05_communication-collaboration-culture.html#collaboration",
    "title": "12  Communication, Collaboration, and Culture (Or Class Choice)",
    "section": "12.2 Collaboration",
    "text": "12.2 Collaboration\n\nSlack, Teams, Discord, oh my!\nCollaboration skills generally\nInterpersonal skills\nHow to network\nHow to take initiative in decision-making and leadership\nHow to get feedback",
    "crumbs": [
      "Data Dissemination",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Communication, Collaboration, and Culture (Or Class Choice)</span>"
    ]
  },
  {
    "objectID": "05_communication-collaboration-culture.html#difficult-conversations",
    "href": "05_communication-collaboration-culture.html#difficult-conversations",
    "title": "12  Communication, Collaboration, and Culture (Or Class Choice)",
    "section": "12.3 Difficult conversations",
    "text": "12.3 Difficult conversations\n\n12.3.1 How can you raise a concern about a certain subject?\n\n\n\n12.3.2 How can you properly disagree appropriately?\n\n\n\n12.3.3 How can you send follow-up emails on time-sensitive items without sounding annoyed or aggressive?",
    "crumbs": [
      "Data Dissemination",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Communication, Collaboration, and Culture (Or Class Choice)</span>"
    ]
  },
  {
    "objectID": "05_communication-collaboration-culture.html#other-communication",
    "href": "05_communication-collaboration-culture.html#other-communication",
    "title": "12  Communication, Collaboration, and Culture (Or Class Choice)",
    "section": "12.4 Other communication",
    "text": "12.4 Other communication\n\n12.4.1 How can you leave an appropriate voicemail (e.g., setting up your answering machine)?\n\n\n\n12.4.2 What are some tips for proper over-the-phone etiquette?\n\n\n\n12.4.3 How should you handle greetings and titles in written and verbal communication, such as when someone has a PhD?",
    "crumbs": [
      "Data Dissemination",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Communication, Collaboration, and Culture (Or Class Choice)</span>"
    ]
  },
  {
    "objectID": "05_data-dissemination-part2.html",
    "href": "05_data-dissemination-part2.html",
    "title": "13  Data Dissemination: Part 2",
    "section": "",
    "text": "13.1 This part of the course is still under construction! To be added by June 21, 2024. Proceed with caution!",
    "crumbs": [
      "Data Dissemination",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Data Dissemination: Part 2</span>"
    ]
  },
  {
    "objectID": "05_data-dissemination-part2.html#this-part-of-the-course-is-still-under-construction-to-be-added-by-june-21-2024.-proceed-with-caution",
    "href": "05_data-dissemination-part2.html#this-part-of-the-course-is-still-under-construction-to-be-added-by-june-21-2024.-proceed-with-caution",
    "title": "13  Data Dissemination: Part 2",
    "section": "",
    "text": "Figure 13.1: Webpage under construction!",
    "crumbs": [
      "Data Dissemination",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Data Dissemination: Part 2</span>"
    ]
  },
  {
    "objectID": "06_data-termination.html",
    "href": "06_data-termination.html",
    "title": "14  Data Destruction or Termination",
    "section": "",
    "text": "14.1 This part of the course is still under construction! To be added by June 28, 2024. Proceed with caution!",
    "crumbs": [
      "Data Destruction and Termination",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Data Destruction or Termination</span>"
    ]
  },
  {
    "objectID": "06_data-termination.html#this-part-of-the-course-is-still-under-construction-to-be-added-by-june-28-2024.-proceed-with-caution",
    "href": "06_data-termination.html#this-part-of-the-course-is-still-under-construction-to-be-added-by-june-28-2024.-proceed-with-caution",
    "title": "14  Data Destruction or Termination",
    "section": "",
    "text": "Figure 14.1: Webpage under construction!\n\n\n\n\n\n\n\n\n\nFigure 14.2: Ron Swanson from the TV Show, “Parks and Recreation,” smashing a phone with a hammer on his work desk.",
    "crumbs": [
      "Data Destruction and Termination",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Data Destruction or Termination</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Barrientos, Andrés F, Aaron R Williams, Joshua Snoke, and Claire McKay\nBowen. 2024. “A Feasibility Study of Differentially Private\nSummary Statistics and Regression Analyses with Evaluations on\nAdministrative and Survey Data.” Journal of the American\nStatistical Association 119 (545): 52–65.\n\n\nBierbrauer, Felix J, Pierre C Boyer, and Andreas Peichl. 2021.\n“Politically Feasible Reforms of Nonlinear Tax Systems.”\nAmerican Economic Review 111 (1): 153–91.\n\n\nBowen, Claire McKay. 2021. Protecting Your Privacy in a Data-Driven\nWorld. Chapman; Hall/CRC.\n\n\n———. 2024. “Government Data of the People, by the People, for the\nPeople: Navigating Citizen Privacy Concerns.” Journal of\nEconomic Perspectives 38 (2): 181–200.\n\n\nChoi, Jung Hyun, Alanna McCargo, Michael Neal, Laurie Goodman, and\nCaitlin Young. 2019. “Explaining the Black-White Homeownership\nGap.” Urban Institute. https://www.urban.org/research/publication/explaining-black-white-homeownership-gap-closer-look-disparities-across-local-markets.\n\n\nDeBacker, Jason, Richard W Evans, and Kerk L Phillips. 2019.\n“Integrating Microsimulation Models of Tax Policy into a Dge\nMacroeconomic Model.” Public Finance Review 47 (2):\n207–75.\n\n\nDenning, Dorothy Elizabeth Robling. 1982. Cryptography and Data\nSecurity. Vol. 112. Addison-Wesley Reading.\n\n\nDrechsler, Jörg. 2022. “Challenges in Measuring Utility for Fully\nSynthetic Data.” In International Conference on Privacy in\nStatistical Databases, 220–33. Springer.\n\n\nDrechsler, Jörg, Stefan Bender, and Susanne Rässler. 2008.\n“Comparing Fully and Partially Synthetic Datasets for Statistical\nDisclosure Control in the German IAB Establishment Panel.”\nTransactions on Data Privacy 1 (December): 105–30.\n\n\nFellegi, Ivan P. 1972. “On the Question of Statistical\nConfidentiality.” Journal of the American Statistical\nAssociation 67 (337): 7–18.\n\n\nFienberg, Stephen E. 1994. “Sharing Statistical Data in the\nBiomedical and Health Sciences: Ethical, Institutional, Legal, and\nProfessional Dimensions.” Annual Review of Public Health\n15 (1): 1–18.\n\n\nFienberg, Stephen E, and Jiashun Jin. 2018. “Statistical\nDisclosure Limitation for~ Data~ Access.” In Encyclopedia of\nDatabase Systems (2nd Ed.).\n\n\nGlickman, Jodi. 2011. Great on the Job: What to Say, How to Say It.\nThe Secrets of Getting Ahead. St. Martin’s Griffin.\n\n\nHu, Jingchen, and Claire McKay Bowen. 2024. “Advancing Microdata\nPrivacy Protection: A Review of Synthetic Data Methods.”\nWiley Interdisciplinary Reviews: Computational Statistics 16\n(1): e1636.\n\n\nICPSR. n.d. “Guide to Social Science Data Preparation and\nArchiving: Best Practice Throughout the Data Life Cycle: 6th\nEdition.” https://www.icpsr.umich.edu/web/pages/deposit/guide/.\n\n\nKitchin, Rob. 2014. The Data Revolution: Big Data, Open Data, Data\nInfrastructures and Their Consequences. Sage.\n\n\nMatthews, Gregory J, and Ofer Harel. 2011. “Data Confidentiality:\nA Review of Methods for Statistical Disclosure Limitation and Methods\nfor Assessing Privacy.”\n\n\nMcClelland, Robert, Daniel Berger, Alyssa Harris, Chenxi Lu, and Kyle\nUeyama. 2019. “The Tcja: What Might Have Been.”\nUrban-Brookings Tax Policy Center.\n\n\nMcKenna, L, and M Haubach. 2019. “Legacy Techniques and Current\nResearch in Disclosure Avoidance at the Us Census Bureau.”\nResearch and Methodology Directorate, US Census Bureau, Washington,\nDC.\n\n\nMitra, Robin, and Jerome P Reiter. 2006. “Adjusting Survey Weights\nWhen Altering Identifying Design Variables via Synthetic Data.”\nIn Privacy in Statistical Databases: CENEX-SDC Project International\nConference, PSD 2006, Rome, Italy, December 13-15, 2006.\nProceedings, 177–88. Springer.\n\n\nReiter, Jerome P, Quanli Wang, and Biyuan Zhang. 2014. “Bayesian\nEstimation of Disclosure Risks for Multiply Imputed, Synthetic\nData.” Journal of Privacy and Confidentiality 6 (1).\n\n\nSchwabish, Jonathan, Donovan Harvey, Mel Langness, Vincent Pancini, Amy\nRogin, and Gabi Velasco. 2023. “Do No Harm Guide: Collecting,\nAnalyzing, and Reporting Gender and Sexual Orientation Data.”\n\n\nSonoda, Paige, and Heather Hahn. 2023. “Disaggregating Data Is\nCritical to Dismantling the Model Minority Stereotype.” https://www.urban.org/urban-wire/disaggregating-data-critical-dismantling-model-minority-stereotype.\n\n\nStern, Alena, and Ajjit Narayanan. 2021. “Ethics and Empathy in\nUsing Imputation to Disaggregate Data for Racial Equity.” https://www.urban.org/research/publication/ethics-and-empathy-using-imputation-disaggregate-data-racial-equity-case-study-imputing-credit-bureau-data.\n\n\nSweeney, Latanya, Akua Abu, and Julia Winn. 2013. “Identifying\nParticipants in the Personal Genome Project by Name (a Re-Identification\nExperiment).” https://arxiv.org/abs/1304.7605.\n\n\nTarran, Brian. 2023. “JSM Session Touches on Equity.”\nAmstat News. https://magazine.amstat.org/blog/2023/11/01/jedi-corner-jsm-session-equity/.\n\n\nTraub, Amy, and Sean McElwee. 2016. “Bad Credit Shouldn’t Block\nEmployment: How to Make State Bans on Employment Credit Checks More\nEffective.” Washington, DC: Demos.\n\n\nTurow, Joseph, Yphtach Lelkes, Nora Draper, and Ari Ezra Waldman. 2023.\n“Americans Can’t Consent to Companies’ Use of Their Data: They\nAdmit They Don’t Understand It, Say They’re Helpless to Control It, and\nBelieve They’re Harmed When Firms Use Their Data–Making What Companies\nDo Illegitimate.” Say They’re Helpless to Control It, and\nBelieve They’re Harmed When Firms Use Their Data–Making What Companies\nDo Illegitimate (February 15, 2023).\n\n\nWilkinson, Mark D, Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle\nAppleton, Myles Axton, Arie Baak, Niklas Blomberg, et al. 2016.\n“The FAIR Guiding Principles for Scientific Data Management and\nStewardship.” Scientific Data 3 (1): 1–9.",
    "crumbs": [
      "References"
    ]
  }
]